{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b40c80f-9d7e-4de0-b8cb-2a2d3d1b8fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run hash (first 10 digits):  2fc5c30143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb293e4b42b4451994fccb49120c2f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011120569444444249, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/amir/PycharmProjects/Medfair/MEDFAIR/wandb/run-20240812_133216-uf8r4g5l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/amir-busiiness-personal/test/runs/uf8r4g5l' target=\"_blank\">baseline</a></strong> to <a href='https://wandb.ai/amir-busiiness-personal/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/amir-busiiness-personal/test' target=\"_blank\">https://wandb.ai/amir-busiiness-personal/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/amir-busiiness-personal/test/runs/uf8r4g5l' target=\"_blank\">https://wandb.ai/amir-busiiness-personal/test/runs/uf8r4g5l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments parsed successfully and wandb initialized.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from netcal.metrics import ECE\n",
    "import wandb\n",
    "from parse_args import collect_args\n",
    "\n",
    "from models.CFair import CFair\n",
    "from models.DomainInd import DomainInd\n",
    "from models.EnD import EnD\n",
    "from models.GroupDRO import GroupDRO\n",
    "from models.LAFTR import LAFTR\n",
    "from models.LNL import LNL\n",
    "from models.ODR import ODR\n",
    "from models.resampling import resampling\n",
    "from models.SWAD import SWAD\n",
    "\n",
    "# Reset sys.argv to avoid issues with Jupyter Notebook's internal arguments\n",
    "sys.argv = ['trainn.py']\n",
    "\n",
    "# Collect arguments\n",
    "opt, wandb = collect_args()\n",
    "\n",
    "print(\"Arguments parsed successfully and wandb initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d816583-a40c-4a3b-b3f6-ccce76d3ce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDataset class and calculate_fairness_metrics function defined successfully.\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['Path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.dataframe.iloc[idx]['binaryLabel']\n",
    "        protected_attr = self.dataframe.iloc[idx]['Age_Category']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        protected_attr = torch.tensor(protected_attr)\n",
    "\n",
    "        return image, label, protected_attr\n",
    "\n",
    "def calculate_fairness_metrics(y_true, y_pred, protected_attr):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    FPR = fp / (fp + tn)\n",
    "    FNR = fn / (fn + tp)\n",
    "    TPR = tp / (tp + fn)\n",
    "    TNR = tn / (tn + fp)\n",
    "    ece = ECE().measure(y_pred, y_true)\n",
    "\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "        'BCE': (FPR + FNR) / 2,\n",
    "        'ECE': ece,\n",
    "        'TPR@80': TPR,\n",
    "        'TNR': TNR,\n",
    "        'FPR': FPR,\n",
    "        'FNR': FNR,\n",
    "        'EqOdd': (FPR + FNR) / 2\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"CustomDataset class and calculate_fairness_metrics function defined successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30a3e4e1-2364-429b-ba6e-ee1820ce3bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed and images saved successfully.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(metadata_path, image_dir):\n",
    "    # Read the Excel file and drop any rows with missing values\n",
    "    metadata = pd.read_excel(metadata_path)\n",
    "    metadata.dropna(inplace=True)\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    train_data, test_data = train_test_split(metadata, test_size=0.2, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "    def save_images_as_pickle(data, save_dir):\n",
    "        # Create the directory if it doesn't exist\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        for idx, row in data.iterrows():\n",
    "            image_path = os.path.join(image_dir, row['Image_filename'])\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"File not found: {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            with Image.open(image_path) as img:\n",
    "                img = img.resize((224, 224))  # Resize the image to 224x224 pixels\n",
    "                img_array = np.array(img)  # Convert the image to a numpy array\n",
    "                pickle_file = os.path.join(save_dir, f\"{row['Image_filename']}.pkl\")  # Path to save the pickle file\n",
    "                \n",
    "                # Save the image array as a pickle file\n",
    "                with open(pickle_file, 'wb') as f:\n",
    "                    pickle.dump(img_array, f)\n",
    "\n",
    "    # Save the images as pickle files in the appropriate directories\n",
    "    save_images_as_pickle(train_data, 'train_images/')\n",
    "    save_images_as_pickle(val_data, 'val_images/')\n",
    "    save_images_as_pickle(test_data, 'test_images/')\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Preprocess the data\n",
    "train_data, val_data, test_data = preprocess_data('BrEaST-Lesions-USG-clinical-data-Dec-15-2023.xlsx', '/Users/amir/PycharmProjects/Medfair/MEDFAIR/BrEaST-Lesions_USG-images_and_masks')\n",
    "\n",
    "print(\"Data preprocessed and images saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cecd9c2d-9440-43aa-9080-ba667fc4b096",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'image_feature_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     final_results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training and evaluation completed successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mopt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m model_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCFair\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDomainInd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroupDRO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAFTR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLNL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mODR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResampling\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSWAD\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 28\u001b[0m models_list \u001b[38;5;241m=\u001b[39m [\u001b[43mCFair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[43m)\u001b[49m, DomainInd(opt, wandb), EnD(opt, wandb), GroupDRO(opt, wandb), \n\u001b[1;32m     29\u001b[0m                LAFTR(opt, wandb), LNL(opt, wandb), ODR(opt, wandb), resampling(opt, wandb), SWAD(opt, wandb)]\n\u001b[1;32m     31\u001b[0m final_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_names, models_list):\n",
      "File \u001b[0;32m~/PycharmProjects/Medfair/MEDFAIR/models/CFair/CFair.py:16\u001b[0m, in \u001b[0;36mCFair.__init__\u001b[0;34m(self, opt, wandb)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, opt, wandb):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCFair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_classes \u001b[38;5;241m=\u001b[39m opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msens_classes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msens_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/PycharmProjects/Medfair/MEDFAIR/models/basenet.py:59\u001b[0m, in \u001b[0;36mBaseNet.__init__\u001b[0;34m(self, opt, wandb)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_3d \u001b[38;5;241m=\u001b[39m opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_3d\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name \u001b[38;5;241m=\u001b[39m opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_tabular:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m#self.in_features = len(self.train_data.data_df.columns) - 1\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m#self.in_features = 10000\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m146\u001b[39m\n",
      "File \u001b[0;32m~/PycharmProjects/Medfair/MEDFAIR/models/basenet.py:73\u001b[0m, in \u001b[0;36mBaseNet.set_data\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, opt):\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set up the dataloaders\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_meta, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_meta \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/Medfair/MEDFAIR/datasets/utils.py:80\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     77\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_seed\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[1;32m     78\u001b[0m     random\u001b[38;5;241m.\u001b[39mseed(opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_seed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 80\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[43mdata_setting\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_feature_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     81\u001b[0m train_meta \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_setting[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_meta_path\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[1;32m     82\u001b[0m val_meta \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_setting[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_meta_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_feature_path'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # تنظیم مسیر فایل‌های پیککل به عنوان image_feature_path\n",
    "    data_setting = {\n",
    "        'image_feature_path': {\n",
    "            'train': 'train_images/',\n",
    "            'val': 'val_images/',\n",
    "            'test': 'test_images/'\n",
    "        },\n",
    "        # سایر تنظیمات...\n",
    "    }\n",
    "\n",
    "    # تعریف transform برای پیش‌پردازش تصاویر\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dataset = CustomDataset(dataframe=train_data, transform=transform)\n",
    "    val_dataset = CustomDataset(dataframe=val_data, transform=transform)\n",
    "    test_dataset = CustomDataset(dataframe=test_data, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=opt['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=opt['batch_size'], shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=opt['batch_size'], shuffle=False)\n",
    "\n",
    "    model_names = ['CFair', 'DomainInd', 'EnD', 'GroupDRO', 'LAFTR', 'LNL', 'ODR', 'Resampling', 'SWAD']\n",
    "    models_list = [CFair(opt, wandb), DomainInd(opt, wandb), EnD(opt, wandb), GroupDRO(opt, wandb), \n",
    "                   LAFTR(opt, wandb), LNL(opt, wandb), ODR(opt, wandb), resampling(opt, wandb), SWAD(opt, wandb)]\n",
    "\n",
    "    final_results = pd.DataFrame()\n",
    "\n",
    "    for model_name, model in zip(model_names, models_list):\n",
    "        if opt['resume_path']:\n",
    "            model.load_state_dict(torch.load(opt['resume_path']))\n",
    "            print(f\"Model {model_name} loaded from {opt['resume_path']}\")\n",
    "\n",
    "        optimizer = optim.SGD(model.parameters(), lr=opt['lr'], momentum=0.9)\n",
    "        trained_model = train_model(model, {'train': train_loader, 'val': val_loader}, nn.CrossEntropyLoss(), optimizer, opt, num_epochs=opt['total_epochs'])\n",
    "\n",
    "        save_path = os.path.join(opt['save_folder'], f\"{model_name}_final.pth\")\n",
    "        torch.save(trained_model.state_dict(), save_path)\n",
    "        print(f\"Model {model_name} saved to {save_path}\")\n",
    "\n",
    "        for age_group in train_data['Age_Category'].unique():\n",
    "            group_data = train_data[train_data['Age_Category'] == age_group]\n",
    "            y_true = group_data['binaryLabel']\n",
    "            y_pred = trained_model.predict(group_data['Path'])  \n",
    "            metrics = calculate_fairness_metrics(y_true, y_pred, age_group)\n",
    "            metrics['Model'] = model_name\n",
    "            metrics['Group'] = f'Grp. {age_group}'\n",
    "            metrics_df = pd.DataFrame([metrics])\n",
    "            final_results = pd.concat([final_results, metrics_df], ignore_index=True)\n",
    "\n",
    "    final_results = final_results.pivot(index='Model', columns='Group')\n",
    "    print(final_results)\n",
    "\n",
    "    final_results.to_csv('final_results.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "print(\"Model training and evaluation completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04e4b8-ee77-4859-a659-064070388f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
