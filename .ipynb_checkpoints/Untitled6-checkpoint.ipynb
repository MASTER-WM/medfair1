{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0394ae49-f768-4d1b-ac07-a5768db3f96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting netcal\n",
      "  Downloading netcal-1.3.6-py3-none-any.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m403.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from netcal) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.4 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from netcal) (1.13.1)\n",
      "Collecting matplotlib<3.8,>=3.3 (from netcal)\n",
      "  Downloading matplotlib-3.7.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from netcal) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.9 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from netcal) (2.3.1)\n",
      "Requirement already satisfied: torchvision>=0.10.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from netcal) (0.18.1)\n",
      "Collecting tqdm>=4.40 (from netcal)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyro-ppl>=1.8 (from netcal)\n",
      "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting tikzplotlib==0.9.8 (from netcal)\n",
      "  Downloading tikzplotlib-0.9.8-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tensorboard>=2.2 (from netcal)\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting gpytorch>=1.5.1 (from netcal)\n",
      "  Downloading gpytorch-1.12-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: Pillow in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from tikzplotlib==0.9.8->netcal) (10.4.0)\n",
      "Requirement already satisfied: mpmath<=1.3,>=0.19 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from gpytorch>=1.5.1->netcal) (1.3.0)\n",
      "Collecting linear-operator>=0.5.2 (from gpytorch>=1.5.1->netcal)\n",
      "  Downloading linear_operator-0.5.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (1.4.5)\n",
      "Collecting numpy>=1.18 (from netcal)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (6.4.0)\n",
      "Collecting opt-einsum>=2.3.2 (from pyro-ppl>=1.8->netcal)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8->netcal)\n",
      "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from scikit-learn>=0.24->netcal) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from scikit-learn>=0.24->netcal) (3.5.0)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.2->netcal)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=2.2->netcal)\n",
      "  Downloading grpcio-1.65.4-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.2->netcal)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting protobuf!=4.24.0,<5.0.0,>=3.19.6 (from tensorboard>=2.2->netcal)\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from tensorboard>=2.2->netcal) (65.5.1)\n",
      "Requirement already satisfied: six>1.9 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from tensorboard>=2.2->netcal) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.2->netcal)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.2->netcal)\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: filelock in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib<3.8,>=3.3->netcal) (3.19.2)\n",
      "Collecting jaxtyping>=0.2.9 (from linear-operator>=0.5.2->gpytorch>=1.5.1->netcal)\n",
      "  Downloading jaxtyping-0.2.33-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typeguard~=2.13.3 (from linear-operator>=0.5.2->gpytorch>=1.5.1->netcal)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2->netcal) (8.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2->netcal) (2.1.5)\n",
      "Downloading netcal-1.3.6-py3-none-any.whl (236 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.3/236.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tikzplotlib-0.9.8-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gpytorch-1.12-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.1/274.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.7.5-cp39-cp39-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.65.4-cp39-cp39-macosx_10_9_universal2.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading linear_operator-0.5.2-py3-none-any.whl (175 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.6/175.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jaxtyping-0.2.33-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: pyro-api, werkzeug, typeguard, tqdm, tensorboard-data-server, protobuf, numpy, grpcio, absl-py, opt-einsum, markdown, jaxtyping, tensorboard, pyro-ppl, matplotlib, linear-operator, tikzplotlib, gpytorch, netcal\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.0\n",
      "    Uninstalling numpy-2.0.0:\n",
      "      Successfully uninstalled numpy-2.0.0\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.9.1\n",
      "    Uninstalling matplotlib-3.9.1:\n",
      "      Successfully uninstalled matplotlib-3.9.1\n",
      "Successfully installed absl-py-2.1.0 gpytorch-1.12 grpcio-1.65.4 jaxtyping-0.2.33 linear-operator-0.5.2 markdown-3.6 matplotlib-3.7.5 netcal-1.3.6 numpy-1.26.4 opt-einsum-3.3.0 protobuf-4.25.4 pyro-api-0.1.2 pyro-ppl-1.9.1 tensorboard-2.17.0 tensorboard-data-server-0.7.2 tikzplotlib-0.9.8 tqdm-4.66.5 typeguard-2.13.3 werkzeug-3.0.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install netcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ed3d7-723e-4e40-b429-c72eba55f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run hash (first 10 digits):  46f6e20059\n",
      "Training ResNet18 model...\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7257 Acc: 0.5146\n",
      "val Loss: 0.7239 Acc: 0.5714\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.6404 Acc: 0.6082\n",
      "val Loss: 0.6043 Acc: 0.6190\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4804 Acc: 0.8246\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import json\n",
    "import hashlib\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, confusion_matrix\n",
    "from netcal.metrics import ECE\n",
    "\n",
    "import sys\n",
    "\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = sys.argv[:1]  # حذف آرگومان‌های ناخواسته\n",
    "\n",
    "# Define paths and read dataset\n",
    "path = '/Users/amir/PycharmProjects/Medfair/MEDFAIR/'\n",
    "demo_data = pd.read_excel(path + 'BrEaST-Lesions-USG-clinical-data-Dec-15-2023.xlsx')\n",
    "images_path = os.path.join(path, '/MEDFAIR/BrEaST-Lesions_USG-images_and_masks/')\n",
    "pathlist = demo_data['Image_filename'].values.tolist()\n",
    "paths = ['/Users/amir/PycharmProjects/Medfair/MEDFAIR/BrEaST-Lesions_USG-images_and_masks/' + i for i in pathlist]\n",
    "demo_data['Path'] = paths\n",
    "\n",
    "# Data preprocessing\n",
    "demo_data = demo_data[~demo_data['Age'].isnull()]\n",
    "age_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "age_labels = ['0-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']\n",
    "demo_data['Age_Category'] = pd.cut(demo_data['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "demo_data['Age_multi'] = demo_data['Age'].values.astype('int')\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(-1, 19), 0, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(20, 39), 1, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(40, 59), 2, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(60, 79), 3, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'] >= 80, 4, demo_data['Age_multi'])\n",
    "\n",
    "demo_data['Age_binary'] = demo_data['Age'].values.astype('int')\n",
    "demo_data['Age_binary'] = np.where(demo_data['Age_binary'].between(-1, 60), 0, demo_data['Age_binary'])\n",
    "demo_data['Age_binary'] = np.where(demo_data['Age_binary'] >= 60, 1, demo_data['Age_binary'])\n",
    "\n",
    "labels = demo_data['Classification'].values.copy()\n",
    "labels[labels == 'malignant'] = '1'\n",
    "labels[labels != '1'] = '0'\n",
    "labels = labels.astype('int')\n",
    "demo_data['binaryLabel'] = labels\n",
    "\n",
    "def split_811(all_meta, patient_ids):\n",
    "    sub_train, sub_val_test = train_test_split(patient_ids, test_size=0.2, random_state=0)\n",
    "    sub_val, sub_test = train_test_split(sub_val_test, test_size=0.5, random_state=0)\n",
    "    train_meta = all_meta[all_meta.CaseID.isin(sub_train)]\n",
    "    val_meta = all_meta[all_meta.CaseID.isin(sub_val)]\n",
    "    test_meta = all_meta[all_meta.CaseID.isin(sub_test)]\n",
    "    return train_meta, val_meta, test_meta\n",
    "\n",
    "sub_train, sub_val, sub_test = split_811(demo_data, np.unique(demo_data['CaseID']))\n",
    "sub_train.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_train.csv')\n",
    "sub_val.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_val.csv')\n",
    "sub_test.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_test.csv')\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['Path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.dataframe.iloc[idx]['binaryLabel']\n",
    "        protected_attr = self.dataframe.iloc[idx]['Age_Category']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, protected_attr\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(dataframe=sub_train, transform=transform)\n",
    "val_dataset = CustomDataset(dataframe=sub_val, transform=transform)\n",
    "test_dataset = CustomDataset(dataframe=sub_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_resnet18.fc.in_features\n",
    "model_resnet18.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "optimizers = [\n",
    "    optim.SGD(model_resnet18.parameters(), lr=0.001, momentum=0.9)\n",
    "]\n",
    "\n",
    "def collect_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--experiment', type=str, choices=['baseline', 'CFair', 'LAFTR', 'resampling'])\n",
    "    parser.add_argument('--sensitive_name', default='Age_Category', choices=['Age_Category'])\n",
    "    parser.add_argument('--random_seed', type=int, default=0)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--lr', type=float, default=1e-4)\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
    "    parser.add_argument('--total_epochs', type=int, default=25)\n",
    "    parser.add_argument('--fair_coeff', type=float, default=1.0)\n",
    "    parser.set_defaults(cuda=False)  # Default to False since CUDA is not available\n",
    "    \n",
    "    opt = vars(parser.parse_args())\n",
    "    opt = create_experiment_setting(opt)\n",
    "    return opt\n",
    "\n",
    "def create_experiment_setting(opt):\n",
    "    run_hash = hashlib.sha1()\n",
    "    run_hash.update(str(time.time()).encode('utf-8'))\n",
    "    opt['hash'] = run_hash.hexdigest()[:10]\n",
    "    print('run hash (first 10 digits): ', opt['hash'])\n",
    "    \n",
    "    opt['device'] = torch.device('cuda' if opt['cuda'] and torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    return opt\n",
    "\n",
    "opt = collect_args()\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, opt, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels, protected_attrs in dataloaders[phase]:\n",
    "                inputs = inputs.to(opt['device'])\n",
    "                labels = labels.to(opt['device'])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        if opt['experiment'] == 'CFair':\n",
    "                            fair_loss = compute_fairness_loss(outputs, protected_attrs, opt['fair_coeff'])\n",
    "                            loss += fair_loss\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        print()\n",
    "\n",
    "    return model\n",
    "\n",
    "device = torch.device(\"cpu\")  # Use CPU as CUDA is not available\n",
    "\n",
    "models_list = [model_resnet18]\n",
    "optimizers = [optim.SGD(model.parameters(), lr=0.001, momentum=0.9) for model in models_list]\n",
    "model_names = ['ResNet18']\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n",
    "\n",
    "trained_models = []\n",
    "\n",
    "for model, optimizer, model_name in zip(models_list, optimizers, model_names):\n",
    "    model = model.to(device)\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    trained_model = train_model(model, dataloaders, criterion, optimizer, opt, num_epochs=opt['total_epochs'])\n",
    "    trained_models.append(trained_model)\n",
    "\n",
    "print(\"Training completed for all models.\")\n",
    "\n",
    "# Define evaluation functions\n",
    "def calculate_fairness_metrics(y_true, y_pred, sensitive_attr):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    FPR = fp / (fp + tn)\n",
    "    FNR = fn / (fn + tp)\n",
    "    TPR = tp / (tp + fn)\n",
    "    TNR = tn / (tn + fp)\n",
    "    PR80_TNR = TPR / TNR if TNR != 0 else np.inf\n",
    "    \n",
    "    BCE = (FPR + FNR) / 2\n",
    "\n",
    "    ece = ECE().measure(y_pred, y_true)\n",
    "    \n",
    "    # Balanced Equalized Odds (BEO) calculation\n",
    "    groups = np.unique(sensitive_attr)\n",
    "    TPR_diff = []\n",
    "    FPR_diff = []\n",
    "    for group in groups:\n",
    "        group_idx = (sensitive_attr == group)\n",
    "        group_y_true = y_true[group_idx]\n",
    "        group_y_pred = y_pred[group_idx]\n",
    "        cm_group = confusion_matrix(group_y_true, group_y_pred)\n",
    "        tn_g, fp_g, fn_g, tp_g = cm_group.ravel()\n",
    "\n",
    "        FPR_g = fp_g / (fp_g + tn_g) if (fp_g + tn_g) > 0 else 0\n",
    "        TPR_g = tp_g / (tp_g + fn_g) if (tp_g + fn_g) > 0 else 0\n",
    "\n",
    "        FPR_diff.append(FPR_g)\n",
    "        TPR_diff.append(TPR_g)\n",
    "    \n",
    "    FPR_diff = np.abs(np.diff(FPR_diff)).sum() / (len(groups) - 1)\n",
    "    TPR_diff = np.abs(np.diff(TPR_diff)).sum() / (len(groups) - 1)\n",
    "\n",
    "    Balanced_EO = (FPR_diff + TPR_diff) / 2\n",
    "    \n",
    "    metrics = {\n",
    "        \"BCE\": BCE,\n",
    "        \"ECE\": ece,\n",
    "        \"FPR\": FPR,\n",
    "        \"FNR\": FNR,\n",
    "        \"PR80_TNR\": PR80_TNR,\n",
    "        \"Balanced_EO\": Balanced_EO\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Evaluate the trained models on the test set\n",
    "def evaluate_model(model, test_loader, opt):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_protected_attrs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, protected_attrs in test_loader:\n",
    "            inputs = inputs.to(opt['device'])\n",
    "            labels = labels.to(opt['device'])\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_protected_attrs.extend(protected_attrs.cpu().numpy())\n",
    "    \n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_protected_attrs = np.array(all_protected_attrs)\n",
    "    \n",
    "    fairness_metrics = calculate_fairness_metrics(all_labels, all_preds, all_protected_attrs)\n",
    "    \n",
    "    return fairness_metrics\n",
    "\n",
    "# Run evaluations\n",
    "print(\"Evaluating models on the test set...\")\n",
    "for model_name, model in zip(model_names, trained_models):\n",
    "    fairness_metrics = evaluate_model(model, test_loader, opt)\n",
    "    print(f\"Fairness metrics for {model_name}: {fairness_metrics}\")\n",
    "\n",
    "# The results should now show BCE, ECE, FPR, FNR, PR @ 80 TNR, and Balanced Equalized Odds for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6913c2-17c4-4324-8ba7-14b2938b404c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
