{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7490ad",
   "metadata": {},
   "source": [
    "# Fairness and Performance Evaluation of Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the transformations for the training and testing sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load and preprocess the datasets\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='path_to_train_dataset', transform=transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root='path_to_test_dataset', transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe98d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    torchvision.models.resnet18(pretrained=True),\n",
    "    torchvision.models.vgg16(pretrained=True),\n",
    "    torchvision.models.densenet121(pretrained=True),\n",
    "    torchvision.models.mobilenet_v2(pretrained=True),\n",
    "    torchvision.models.alexnet(pretrained=True)\n",
    "]\n",
    "\n",
    "# Modify the final layer to match the number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "for model in models:\n",
    "    if hasattr(model, 'fc'):\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif hasattr(model, 'classifier'):\n",
    "        if isinstance(model.classifier, nn.Sequential):\n",
    "            model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)\n",
    "        else:\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a0497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the training function\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac860fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train all models\n",
    "trained_models = []\n",
    "model_names = ['ResNet18', 'VGG16', 'DenseNet121', 'MobileNetV2', 'AlexNet']\n",
    "for model, model_name in zip(models, model_names):\n",
    "    print(f\"Training {model_name}...\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "    trained_model = train_model(model, dataloaders, criterion, optimizer, num_epochs=25)\n",
    "    trained_models.append(trained_model)\n",
    "    torch.save(trained_model.state_dict(), f'model_{model_name}.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_model(model, dataloader, protected_attr_name='Age_Category'):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_protected_attrs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_protected_attrs.extend(inputs.cpu().numpy()[:, protected_attr_name])\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_protected_attrs = np.array(all_protected_attrs)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    dp = {group: np.mean(all_preds[all_protected_attrs == group]) for group in np.unique(all_protected_attrs)}\n",
    "    eo = {group: {'TPR': np.mean((all_preds == 1) & (all_labels == 1) & (all_protected_attrs == group)),\n",
    "                  'FPR': np.mean((all_preds == 1) & (all_labels == 0) & (all_protected_attrs == group))} \n",
    "          for group in np.unique(all_protected_attrs)}\n",
    "    return dp, eo, accuracy, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate fairness and performance metrics for each trained model\n",
    "for model, model_name in zip(trained_models, model_names):\n",
    "    print(f\"Evaluating fairness and performance metrics for {model_name}...\")\n",
    "    dp, eo, accuracy, f1 = evaluate_model(model, test_loader, protected_attr_name='Age_Category')\n",
    "    print(f\"Demographic Parity for {model_name}: {dp}\")\n",
    "    print(f\"Equalized Odds for {model_name}: {eo}\")\n",
    "    print(f\"Accuracy for {model_name}: {accuracy}\")\n",
    "    print(f\"F1 Score for {model_name}: {f1}\")\n",
    "    print()\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
