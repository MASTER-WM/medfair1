{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127bf040",
   "metadata": {},
   "source": [
    "# محاسبه متریک‌های انصاف (Fairness Metrics) بر اساس داده‌های مدل‌های مختلف"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ffa096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from netcal.metrics import ECE\n",
    "\n",
    "# تابع برای محاسبه متریک‌های انصاف\n",
    "def evaluate_model(model, test_loader, opt):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_protected_attrs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, protected_attrs in test_loader:\n",
    "            inputs = inputs.to(opt['device'])\n",
    "            labels = labels.to(opt['device'])\n",
    "\n",
    "            preds = model(inputs)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.argmax(dim=1).cpu().numpy())  # تبدیل احتمالات به برچسب‌های کلاس\n",
    "            all_protected_attrs.extend(protected_attrs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_protected_attrs = np.array(all_protected_attrs)\n",
    "\n",
    "    # محاسبه متریک‌ها\n",
    "    metrics = {}\n",
    "    for group in np.unique(all_protected_attrs):\n",
    "        group_idx = all_protected_attrs == group\n",
    "        y_true = all_labels[group_idx]\n",
    "        y_pred = all_preds[group_idx]\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "        FPR = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        FNR = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        TPR = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        TNR = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "        # محاسبه متریک‌های نهایی\n",
    "        metrics[group] = {\n",
    "            'BCE': (FPR + FNR) / 2,\n",
    "            'ECE': ECE().measure(y_pred, y_true),\n",
    "            'TPR@80': TPR,\n",
    "            'TNR': TNR,\n",
    "            'FPR': FPR,\n",
    "            'FNR': FNR,\n",
    "            'EqOdd': (FPR + FNR) / 2  # شبیه سازی EqOdd با استفاده از BCE\n",
    "        }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# مدل‌ها را ارزیابی کنید و نتایج را در قالب یک DataFrame قرار دهید\n",
    "final_results = pd.DataFrame()\n",
    "\n",
    "for model_name, model in zip(model_names, trained_models):\n",
    "    fairness_metrics = evaluate_model(model, test_loader, opt)\n",
    "    for group, metrics in fairness_metrics.items():\n",
    "        metrics['Model'] = model_name\n",
    "        metrics['Group'] = f'Grp. {group}'\n",
    "        final_results = final_results.append(metrics, ignore_index=True)\n",
    "\n",
    "# مرتب سازی نهایی جدول برای نمایش مشابه تصویر\n",
    "final_results = final_results.pivot_table(index=['Model', 'Group'], columns=final_results.columns.difference(['Model', 'Group']), aggfunc='first')\n",
    "\n",
    "final_results\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
