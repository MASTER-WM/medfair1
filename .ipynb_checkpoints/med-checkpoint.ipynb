{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0394ae49-f768-4d1b-ac07-a5768db3f96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting netcal\n",
      "  Downloading netcal-1.3.6-py3-none-any.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m403.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from netcal) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.4 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from netcal) (1.13.1)\n",
      "Collecting matplotlib<3.8,>=3.3 (from netcal)\n",
      "  Downloading matplotlib-3.7.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from netcal) (1.5.1)\n",
      "Requirement already satisfied: torch>=1.9 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from netcal) (2.3.1)\n",
      "Requirement already satisfied: torchvision>=0.10.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from netcal) (0.18.1)\n",
      "Collecting tqdm>=4.40 (from netcal)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyro-ppl>=1.8 (from netcal)\n",
      "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting tikzplotlib==0.9.8 (from netcal)\n",
      "  Downloading tikzplotlib-0.9.8-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tensorboard>=2.2 (from netcal)\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting gpytorch>=1.5.1 (from netcal)\n",
      "  Downloading gpytorch-1.12-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: Pillow in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from tikzplotlib==0.9.8->netcal) (10.4.0)\n",
      "Requirement already satisfied: mpmath<=1.3,>=0.19 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from gpytorch>=1.5.1->netcal) (1.3.0)\n",
      "Collecting linear-operator>=0.5.2 (from gpytorch>=1.5.1->netcal)\n",
      "  Downloading linear_operator-0.5.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (1.4.5)\n",
      "Collecting numpy>=1.18 (from netcal)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from matplotlib<3.8,>=3.3->netcal) (6.4.0)\n",
      "Collecting opt-einsum>=2.3.2 (from pyro-ppl>=1.8->netcal)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8->netcal)\n",
      "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from scikit-learn>=0.24->netcal) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from scikit-learn>=0.24->netcal) (3.5.0)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.2->netcal)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=2.2->netcal)\n",
      "  Downloading grpcio-1.65.4-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.2->netcal)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting protobuf!=4.24.0,<5.0.0,>=3.19.6 (from tensorboard>=2.2->netcal)\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from tensorboard>=2.2->netcal) (65.5.1)\n",
      "Requirement already satisfied: six>1.9 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from tensorboard>=2.2->netcal) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.2->netcal)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.2->netcal)\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: filelock in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from torch>=1.9->netcal) (2024.6.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib<3.8,>=3.3->netcal) (3.19.2)\n",
      "Collecting jaxtyping>=0.2.9 (from linear-operator>=0.5.2->gpytorch>=1.5.1->netcal)\n",
      "  Downloading jaxtyping-0.2.33-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typeguard~=2.13.3 (from linear-operator>=0.5.2->gpytorch>=1.5.1->netcal)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2->netcal) (8.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2->netcal) (2.1.5)\n",
      "Downloading netcal-1.3.6-py3-none-any.whl (236 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.3/236.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tikzplotlib-0.9.8-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gpytorch-1.12-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.1/274.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.7.5-cp39-cp39-macosx_11_0_arm64.whl (7.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.65.4-cp39-cp39-macosx_10_9_universal2.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading linear_operator-0.5.2-py3-none-any.whl (175 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.6/175.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jaxtyping-0.2.33-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: pyro-api, werkzeug, typeguard, tqdm, tensorboard-data-server, protobuf, numpy, grpcio, absl-py, opt-einsum, markdown, jaxtyping, tensorboard, pyro-ppl, matplotlib, linear-operator, tikzplotlib, gpytorch, netcal\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.0\n",
      "    Uninstalling numpy-2.0.0:\n",
      "      Successfully uninstalled numpy-2.0.0\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.9.1\n",
      "    Uninstalling matplotlib-3.9.1:\n",
      "      Successfully uninstalled matplotlib-3.9.1\n",
      "Successfully installed absl-py-2.1.0 gpytorch-1.12 grpcio-1.65.4 jaxtyping-0.2.33 linear-operator-0.5.2 markdown-3.6 matplotlib-3.7.5 netcal-1.3.6 numpy-1.26.4 opt-einsum-3.3.0 protobuf-4.25.4 pyro-api-0.1.2 pyro-ppl-1.9.1 tensorboard-2.17.0 tensorboard-data-server-0.7.2 tikzplotlib-0.9.8 tqdm-4.66.5 typeguard-2.13.3 werkzeug-3.0.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install netcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "147ed3d7-723e-4e40-b429-c72eba55f5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run hash (first 10 digits):  338e8abe92\n",
      "Training ResNet18...\n",
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.7456 Acc: 0.4912\n",
      "val Loss: 0.7178 Acc: 0.5238\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.6086 Acc: 0.6725\n",
      "val Loss: 0.6920 Acc: 0.6190\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.4619 Acc: 0.8655\n",
      "val Loss: 0.6344 Acc: 0.7143\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.3724 Acc: 0.8713\n",
      "val Loss: 0.5941 Acc: 0.7143\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2698 Acc: 0.9532\n",
      "val Loss: 0.5723 Acc: 0.7619\n",
      "\n",
      "ResNet18 trained and saved.\n",
      "Training VGG16...\n",
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.6831 Acc: 0.5556\n",
      "val Loss: 0.7003 Acc: 0.5714\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.6392 Acc: 0.5965\n",
      "val Loss: 0.6378 Acc: 0.6190\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.6070 Acc: 0.7018\n",
      "val Loss: 0.6231 Acc: 0.5238\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.5345 Acc: 0.7076\n",
      "val Loss: 0.5645 Acc: 0.7619\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.4980 Acc: 0.7544\n",
      "val Loss: 0.9386 Acc: 0.5714\n",
      "\n",
      "VGG16 trained and saved.\n",
      "Training DenseNet121...\n",
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.6879 Acc: 0.5673\n",
      "val Loss: 0.6519 Acc: 0.7143\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.6115 Acc: 0.6842\n",
      "val Loss: 0.7422 Acc: 0.5714\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.5316 Acc: 0.6784\n",
      "val Loss: 0.6643 Acc: 0.5714\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.4355 Acc: 0.8304\n",
      "val Loss: 0.5791 Acc: 0.6190\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2902 Acc: 0.9357\n",
      "val Loss: 0.8100 Acc: 0.5714\n",
      "\n",
      "DenseNet121 trained and saved.\n",
      "Training MobileNetV2...\n",
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.7725 Acc: 0.4854\n",
      "val Loss: 0.6621 Acc: 0.6190\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.6194 Acc: 0.6608\n",
      "val Loss: 0.6579 Acc: 0.6190\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.5381 Acc: 0.7602\n",
      "val Loss: 0.6306 Acc: 0.5714\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.4791 Acc: 0.7778\n",
      "val Loss: 0.5614 Acc: 0.7143\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.4006 Acc: 0.8480\n",
      "val Loss: 0.5496 Acc: 0.7619\n",
      "\n",
      "MobileNetV2 trained and saved.\n",
      "Training AlexNet...\n",
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.6883 Acc: 0.5556\n",
      "val Loss: 0.6157 Acc: 0.6190\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.6139 Acc: 0.6550\n",
      "val Loss: 0.6220 Acc: 0.5714\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.5080 Acc: 0.7661\n",
      "val Loss: 0.6982 Acc: 0.6667\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.5391 Acc: 0.7485\n",
      "val Loss: 0.6113 Acc: 0.7143\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.4630 Acc: 0.7778\n",
      "val Loss: 0.5534 Acc: 0.7143\n",
      "\n",
      "AlexNet trained and saved.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import json\n",
    "import hashlib\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, confusion_matrix\n",
    "from netcal.metrics import ECE\n",
    "\n",
    "import sys\n",
    "\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = sys.argv[:1]  # حذف آرگومان‌های ناخواسته\n",
    "\n",
    "# Define paths and read dataset\n",
    "path = '/Users/amir/PycharmProjects/Medfair/MEDFAIR/'\n",
    "demo_data = pd.read_excel(path + 'BrEaST-Lesions-USG-clinical-data-Dec-15-2023.xlsx')\n",
    "images_path = os.path.join(path, '/MEDFAIR/BrEaST-Lesions_USG-images_and_masks/')\n",
    "pathlist = demo_data['Image_filename'].values.tolist()\n",
    "paths = ['/Users/amir/PycharmProjects/Medfair/MEDFAIR/BrEaST-Lesions_USG-images_and_masks/' + i for i in pathlist]\n",
    "demo_data['Path'] = paths\n",
    "\n",
    "# Data preprocessing\n",
    "demo_data = demo_data[~demo_data['Age'].isnull()]\n",
    "age_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "age_labels = ['0-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']\n",
    "demo_data['Age_Category'] = pd.cut(demo_data['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "demo_data['Age_multi'] = demo_data['Age'].values.astype('int')\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(-1, 19), 0, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(20, 39), 1, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(40, 59), 2, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(60, 79), 3, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'] >= 80, 4, demo_data['Age_multi'])\n",
    "\n",
    "demo_data['Age_binary'] = demo_data['Age'].values.astype('int')\n",
    "demo_data['Age_binary'] = np.where(demo_data['Age_binary'].between(-1, 60), 0, demo_data['Age_binary'])\n",
    "demo_data['Age_binary'] = np.where(demo_data['Age_binary'] >= 60, 1, demo_data['Age_binary'])\n",
    "\n",
    "labels = demo_data['Classification'].values.copy()\n",
    "labels[labels == 'malignant'] = '1'\n",
    "labels[labels != '1'] = '0'\n",
    "labels = labels.astype('int')\n",
    "demo_data['binaryLabel'] = labels\n",
    "\n",
    "def split_811(all_meta, patient_ids):\n",
    "    sub_train, sub_val_test = train_test_split(patient_ids, test_size=0.2, random_state=0)\n",
    "    sub_val, sub_test = train_test_split(sub_val_test, test_size=0.5, random_state=0)\n",
    "    train_meta = all_meta[all_meta.CaseID.isin(sub_train)]\n",
    "    val_meta = all_meta[all_meta.CaseID.isin(sub_val)]\n",
    "    test_meta = all_meta[all_meta.CaseID.isin(sub_test)]\n",
    "    return train_meta, val_meta, test_meta\n",
    "\n",
    "sub_train, sub_val, sub_test = split_811(demo_data, np.unique(demo_data['CaseID']))\n",
    "sub_train.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_train.csv')\n",
    "sub_val.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_val.csv')\n",
    "sub_test.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_test.csv')\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['Path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.dataframe.iloc[idx]['binaryLabel']\n",
    "        protected_attr = self.dataframe.iloc[idx]['Age_Category']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, protected_attr\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(dataframe=sub_train, transform=transform)\n",
    "val_dataset = CustomDataset(dataframe=sub_val, transform=transform)\n",
    "test_dataset = CustomDataset(dataframe=sub_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the models\n",
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_resnet18.fc.in_features\n",
    "model_resnet18.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_vgg16 = models.vgg16(pretrained=True)\n",
    "num_ftrs = model_vgg16.classifier[6].in_features\n",
    "model_vgg16.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_densenet = models.densenet121(pretrained=True)\n",
    "num_ftrs = model_densenet.classifier.in_features\n",
    "model_densenet.classifier = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "num_ftrs = model_mobilenet.classifier[1].in_features\n",
    "model_mobilenet.classifier[1] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_alexnet = models.alexnet(pretrained=True)\n",
    "num_ftrs = model_alexnet.classifier[6].in_features\n",
    "model_alexnet.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Criterion and optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizers = [\n",
    "    optim.SGD(model_resnet18.parameters(), lr=0.001, momentum=0.9),\n",
    "    optim.SGD(model_vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "]\n",
    "\n",
    "optimizers = [\n",
    "    optim.SGD(model_resnet18.parameters(), lr=0.001, momentum=0.9)\n",
    "]\n",
    "\n",
    "def collect_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--experiment', type=str, choices=['baseline', 'CFair', 'LAFTR', 'resampling'])\n",
    "    parser.add_argument('--sensitive_name', default='Age_Category', choices=['Age_Category'])\n",
    "    parser.add_argument('--random_seed', type=int, default=0)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--lr', type=float, default=1e-4)\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
    "    parser.add_argument('--total_epochs', type=int, default=5)\n",
    "    parser.add_argument('--fair_coeff', type=float, default=1.0)\n",
    "    parser.set_defaults(cuda=False)  # Default to False since CUDA is not available\n",
    "    \n",
    "    opt = vars(parser.parse_args())\n",
    "    opt = create_experiment_setting(opt)\n",
    "    return opt\n",
    "\n",
    "def create_experiment_setting(opt):\n",
    "    run_hash = hashlib.sha1()\n",
    "    run_hash.update(str(time.time()).encode('utf-8'))\n",
    "    opt['hash'] = run_hash.hexdigest()[:10]\n",
    "    print('run hash (first 10 digits): ', opt['hash'])\n",
    "    \n",
    "    opt['device'] = torch.device('cuda' if opt['cuda'] and torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    return opt\n",
    "\n",
    "opt = collect_args()\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, opt, num_epochs= 5 ):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels, protected_attrs in dataloaders[phase]:\n",
    "                inputs = inputs.to(opt['device'])\n",
    "                labels = labels.to(opt['device'])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        if opt['experiment'] == 'CFair':\n",
    "                            fair_loss = compute_fairness_loss(outputs, protected_attrs, opt['fair_coeff'])\n",
    "                            loss += fair_loss\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        print()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the models\n",
    "device = torch.device(\"cpu\")  # Use CPU as CUDA is not available\n",
    "\n",
    "models_list = [model_resnet18, model_vgg16, model_densenet, model_mobilenet, model_alexnet]\n",
    "optimizers = [optim.SGD(model.parameters(), lr=0.001, momentum=0.9) for model in models_list]\n",
    "model_names = ['ResNet18', 'VGG16', 'DenseNet121', 'MobileNetV2', 'AlexNet']\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n",
    "\n",
    "trained_models = []\n",
    "\n",
    "for model, optimizer, model_name in zip(models_list, optimizers, model_names):\n",
    "    model = model.to(device)\n",
    "    print(f\"Training {model_name}...\")\n",
    "    trained_model = train_model(model, dataloaders, criterion, optimizer, opt, num_epochs=5)\n",
    "    trained_models.append(trained_model)\n",
    "    torch.save(trained_model.state_dict(), f'model_{model_name}.pth')\n",
    "    print(f\"{model_name} trained and saved.\")\n",
    "\n",
    "# Define evaluation functions\n",
    "def calculate_fairness_metrics(y_true, y_pred, sensitive_attr):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    FPR = fp / (fp + tn)\n",
    "    FNR = fn / (fn + tp)\n",
    "    TPR = tp / (tp + fn)\n",
    "    TNR = tn / (tn + fp)\n",
    "    PR80_TNR = TPR / TNR if TNR != 0 else np.inf\n",
    "    \n",
    "    BCE = (FPR + FNR) / 2\n",
    "\n",
    "    ece = ECE().measure(y_pred, y_true)\n",
    "    \n",
    "    # Balanced Equalized Odds (BEO) calculation\n",
    "    groups = np.unique(sensitive_attr)\n",
    "    TPR_diff = []\n",
    "    FPR_diff = []\n",
    "    for group in groups:\n",
    "        group_idx = (sensitive_attr == group)\n",
    "        group_y_true = y_true[group_idx]\n",
    "        group_y_pred = y_pred[group_idx]\n",
    "        cm_group = confusion_matrix(group_y_true, group_y_pred)\n",
    "        tn_g, fp_g, fn_g, tp_g = cm_group.ravel()\n",
    "\n",
    "        FPR_g = fp_g / (fp_g + tn_g) if (fp_g + tn_g) > 0 else 0\n",
    "        TPR_g = tp_g / (tp_g + fn_g) if (tp_g + fn_g) > 0 else 0\n",
    "\n",
    "        FPR_diff.append(FPR_g)\n",
    "        TPR_diff.append(TPR_g)\n",
    "    \n",
    "    FPR_diff = np.abs(np.diff(FPR_diff)).sum() / (len(groups) - 1)\n",
    "    TPR_diff = np.abs(np.diff(TPR_diff)).sum() / (len(groups) - 1)\n",
    "\n",
    "    Balanced_EO = (FPR_diff + TPR_diff) / 2\n",
    "    \n",
    "    metrics = {\n",
    "        \"BCE\": BCE,\n",
    "        \"ECE\": ece,\n",
    "        \"FPR\": FPR,\n",
    "        \"FNR\": FNR,\n",
    "        \"PR80_TNR\": PR80_TNR,\n",
    "        \"Balanced_EO\": Balanced_EO\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6913c2-17c4-4324-8ba7-14b2938b404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "def expected_calibration_error(y_true, y_pred):\n",
    "    y_pred = y_pred.astype(np.float32)\n",
    "    ece = ECE()\n",
    "    return ece.measure(y_pred, y_true)\n",
    "\n",
    "def false_positive_rate(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, _, _ = cm.ravel()\n",
    "    return fp / (fp + tn)\n",
    "\n",
    "def false_negative_rate(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    _, _, fn, tp = cm.ravel()\n",
    "    return fn / (fn + tp)\n",
    "\n",
    "def pr_at_tnr(y_true, y_pred, threshold=0.8):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    idx = np.argmax(fpr >= threshold)\n",
    "    return tpr[idx]\n",
    "\n",
    "def balanced_equalized_odds(y_true, y_pred, protected_attrs):\n",
    "    groups = np.unique(protected_attrs)\n",
    "    fpr_diff = []\n",
    "    fnr_diff = []\n",
    "    \n",
    "    for group in groups:\n",
    "        group_idx = (protected_attrs == group)\n",
    "        group_y_true = y_true[group_idx]\n",
    "        group_y_pred = y_pred[group_idx]\n",
    "        \n",
    "        fpr_diff.append(false_positive_rate(group_y_true, group_y_pred))\n",
    "        fnr_diff.append(false_negative_rate(group_y_true, group_y_pred))\n",
    "    \n",
    "    fpr_diff = np.abs(np.diff(fpr_diff)).sum() / (len(groups) - 1)\n",
    "    fnr_diff = np.abs(np.diff(fnr_diff)).sum() / (len(groups) - 1)\n",
    "    \n",
    "    return (fpr_diff + fnr_diff) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a5665e-7ecc-4abc-bc57-413ce044b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ایجاد یک نگاشت از دسته‌بندی‌ها به اعداد\n",
    "age_category_mapping = {\n",
    "    '0-10': 0,\n",
    "    '11-20': 1,\n",
    "    '21-30': 2,\n",
    "    '31-40': 3,\n",
    "    '41-50': 4,\n",
    "    '51-60': 5,\n",
    "    '61-70': 6,\n",
    "    '71-80': 7,\n",
    "    '81-90': 8,\n",
    "    '91-100': 9\n",
    "}\n",
    "\n",
    "def evaluate_model(model, test_loader, opt):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_protected_attrs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, protected_attrs in test_loader:\n",
    "            inputs = inputs.to(opt['device'])\n",
    "            labels = labels.to(opt['device'])\n",
    "\n",
    "            # نگاشت protected_attrs به کدهای عددی با استفاده از age_category_mapping\n",
    "            if isinstance(protected_attrs, str):\n",
    "                protected_attrs = torch.tensor([age_category_mapping[protected_attrs]]).to(opt['device'])\n",
    "            else:\n",
    "                # اگر protected_attrs یک آرایه یا لیست از دسته‌بندی‌ها بود\n",
    "                protected_attrs = torch.tensor([age_category_mapping[attr] for attr in protected_attrs]).to(opt['device'])\n",
    "\n",
    "            preds = model(inputs)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.argmax(dim=1).cpu().numpy())  # تبدیل احتمالات به برچسب‌های کلاس\n",
    "            all_protected_attrs.extend(protected_attrs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_protected_attrs = np.array(all_protected_attrs)\n",
    "\n",
    "    fairness_metrics = {\n",
    "        'BCE': balanced_accuracy_score(all_labels, all_preds),\n",
    "        'ECE': expected_calibration_error(all_labels, all_preds),\n",
    "        'FPR': false_positive_rate(all_labels, all_preds),\n",
    "        'FNR': false_negative_rate(all_labels, all_preds),\n",
    "        'PR @ 80 TNR': pr_at_tnr(all_labels, all_preds, threshold=0.8),\n",
    "        'Balanced Equalized Odds': balanced_equalized_odds(all_labels, all_preds, all_protected_attrs),\n",
    "    }\n",
    "\n",
    "    return fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd49522c-fe00-44a7-ae4e-02d36323f3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models on the test set...\n",
      "Fairness metrics for ResNet18: {'BCE': 0.811965811965812, 'ECE': 0.18181806260889227, 'FPR': 0.15384615384615385, 'FNR': 0.2222222222222222, 'PR @ 80 TNR': 1.0, 'Balanced Equalized Odds': 0.375}\n",
      "Fairness metrics for VGG16: {'BCE': 0.5, 'ECE': 0.40909078988161957, 'FPR': 0.0, 'FNR': 1.0, 'PR @ 80 TNR': 1.0, 'Balanced Equalized Odds': 0.0}\n",
      "Fairness metrics for DenseNet121: {'BCE': 0.5, 'ECE': 0.40909078988161957, 'FPR': 0.0, 'FNR': 1.0, 'PR @ 80 TNR': 1.0, 'Balanced Equalized Odds': 0.0}\n",
      "Fairness metrics for MobileNetV2: {'BCE': 0.7564102564102564, 'ECE': 0.2272726080634377, 'FPR': 0.15384615384615385, 'FNR': 0.3333333333333333, 'PR @ 80 TNR': 1.0, 'Balanced Equalized Odds': 0.6875}\n",
      "Fairness metrics for AlexNet: {'BCE': 0.6452991452991452, 'ECE': 0.3181816989725287, 'FPR': 0.15384615384615385, 'FNR': 0.5555555555555556, 'PR @ 80 TNR': 1.0, 'Balanced Equalized Odds': 0.3541666666666667}\n"
     ]
    }
   ],
   "source": [
    "# ارزیابی مدل‌ها\n",
    "print(\"Evaluating models on the test set...\")\n",
    "for model_name, model in zip(model_names, trained_models):\n",
    "    fairness_metrics = evaluate_model(model, test_loader, opt)\n",
    "    print(f\"Fairness metrics for {model_name}: {fairness_metrics}\")\n",
    "\n",
    "# نتایج باید اکنون شامل BCE، ECE، FPR، FNR، PR @ 80 TNR و Balanced Equalized Odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432496ac-e878-46cc-ad54-6e2ca1be653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              BCE       ECE       FPR       FNR  PR @ 80 TNR  \\\n",
      "AlexNet  0.645299  0.318182  0.153846  0.555556          1.0   \n",
      "\n",
      "         Balanced Equalized Odds  \n",
      "AlexNet                 0.354167  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# تبدیل دیکشنری به DataFrame\n",
    "fairness_df = pd.DataFrame([fairness_metrics], index=[model_name])\n",
    "\n",
    "# چاپ نتایج به صورت جدول\n",
    "print(fairness_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65303828-11c5-4a35-8f78-35da5dba0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"BCE\": 0.6452991452991452,\n",
      "    \"ECE\": 0.3181816989725287,\n",
      "    \"FPR\": 0.15384615384615385,\n",
      "    \"FNR\": 0.5555555555555556,\n",
      "    \"PR @ 80 TNR\": 1.0,\n",
      "    \"Balanced Equalized Odds\": 0.3541666666666667\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# چاپ نتایج به صورت مرتب شده\n",
    "print(json.dumps(fairness_metrics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb35fe3-0aaa-46b1-9109-5a7cb9e5e722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet\n",
      "BCE: 0.6452991452991452\n",
      "Balanced Equalized Odds: 0.3541666666666667\n",
      "ECE: 0.3181816989725287\n",
      "FNR: 0.5555555555555556\n",
      "FPR: 0.15384615384615385\n",
      "PR @ 80 TNR: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(model_name)\n",
    "\n",
    "for metric, value in sorted(fairness_metrics.items()):\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea67d0d-549c-4f3e-acc4-ef21bf033eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
