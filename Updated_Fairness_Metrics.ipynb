{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ffa096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run hash (first 10 digits):  f1b5540fa6\n",
      "Training ResNet18...\n",
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.6671 Acc: 0.5673\n",
      "val Loss: 0.6598 Acc: 0.5714\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.5506 Acc: 0.7018\n",
      "val Loss: 0.5907 Acc: 0.6667\n",
      "\n",
      "ResNet18 trained and saved.\n",
      "Training VGG16...\n",
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.7111 Acc: 0.5731\n",
      "val Loss: 0.6973 Acc: 0.5714\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.6491\n",
      "val Loss: 0.6498 Acc: 0.4762\n",
      "\n",
      "VGG16 trained and saved.\n",
      "Training DenseNet121...\n",
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.7306 Acc: 0.5556\n",
      "val Loss: 0.7321 Acc: 0.6190\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.6046 Acc: 0.7076\n",
      "val Loss: 0.5994 Acc: 0.5714\n",
      "\n",
      "DenseNet121 trained and saved.\n",
      "Training MobileNetV2...\n",
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.6987 Acc: 0.5614\n",
      "val Loss: 0.6165 Acc: 0.6190\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.6426 Acc: 0.6316\n",
      "val Loss: 0.5570 Acc: 0.7143\n",
      "\n",
      "MobileNetV2 trained and saved.\n",
      "Training AlexNet...\n",
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.6964 Acc: 0.5731\n",
      "val Loss: 0.6161 Acc: 0.5714\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.5413 Acc: 0.7310\n",
      "val Loss: 0.5691 Acc: 0.7143\n",
      "\n",
      "AlexNet trained and saved.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "data type <class 'numpy.int64'> not inexact",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 379\u001b[0m\n\u001b[1;32m    376\u001b[0m final_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model_names, trained_models):\n\u001b[0;32m--> 379\u001b[0m     fairness_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group, metrics \u001b[38;5;129;01min\u001b[39;00m fairness_metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    381\u001b[0m         metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model_name\n",
      "Cell \u001b[0;32mIn[3], line 365\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_loader, opt)\u001b[0m\n\u001b[1;32m    360\u001b[0m     TNR \u001b[38;5;241m=\u001b[39m tn \u001b[38;5;241m/\u001b[39m (tn \u001b[38;5;241m+\u001b[39m fp) \u001b[38;5;28;01mif\u001b[39;00m (tn \u001b[38;5;241m+\u001b[39m fp) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# محاسبه متریک‌های نهایی\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     metrics[group] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBCE\u001b[39m\u001b[38;5;124m'\u001b[39m: (FPR \u001b[38;5;241m+\u001b[39m FNR) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m--> 365\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mECE\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mECE\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTPR@80\u001b[39m\u001b[38;5;124m'\u001b[39m: TPR,\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTNR\u001b[39m\u001b[38;5;124m'\u001b[39m: TNR,\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFPR\u001b[39m\u001b[38;5;124m'\u001b[39m: FPR,\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFNR\u001b[39m\u001b[38;5;124m'\u001b[39m: FNR,\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEqOdd\u001b[39m\u001b[38;5;124m'\u001b[39m: (FPR \u001b[38;5;241m+\u001b[39m FNR) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# شبیه سازی EqOdd با استفاده از BCE\u001b[39;00m\n\u001b[1;32m    371\u001b[0m     }\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/netcal/metrics/confidence/ECE.py:115\u001b[0m, in \u001b[0;36mECE.measure\u001b[0;34m(self, X, y, batched, uncertainty, return_map, return_num_samples, return_uncertainty_map)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmeasure\u001b[39m(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     59\u001b[0m         X: Union[Iterable[np\u001b[38;5;241m.\u001b[39mndarray], np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m         return_uncertainty_map: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     66\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;28mfloat\u001b[39m, Tuple]:\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    Measure calibration by given predictions with confidence and the according ground truth.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Assume binary predictions with y=1.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m        If 'return_uncertainty' is True, return tuple and append the average standard deviation of confidence within each bin (excluding confidence dimension).\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_measure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mece\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muncertainty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muncertainty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_num_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_num_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_uncertainty_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_uncertainty_map\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/netcal/metrics/Miscalibration.py:665\u001b[0m, in \u001b[0;36m_Miscalibration._measure\u001b[0;34m(self, X, y, metric, batched, uncertainty, return_map, return_num_samples, return_uncertainty_map)\u001b[0m\n\u001b[1;32m    662\u001b[0m     metric \u001b[38;5;241m=\u001b[39m metric\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# prepare input data\u001b[39;00m\n\u001b[0;32m--> 665\u001b[0m X, matched, sample_uncertainty, bin_bounds, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muncertainty\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m# iterate over all batches of X and matched and calculate average miscalibration\u001b[39;00m\n\u001b[1;32m    668\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/netcal/metrics/Miscalibration.py:191\u001b[0m, in \u001b[0;36m_Miscalibration.prepare\u001b[0;34m(self, X, y, batched, uncertainty)\u001b[0m\n\u001b[1;32m    187\u001b[0m sample_uncertainty\u001b[38;5;241m.\u001b[39mappend(batch_uncertainty)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# check and prepare input data\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m batch_X, batch_y, batch_matched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m X[i], y[i] \u001b[38;5;241m=\u001b[39m batch_X, batch_y\n\u001b[1;32m    193\u001b[0m matched\u001b[38;5;241m.\u001b[39mappend(batch_matched)\n",
      "File \u001b[0;32m~/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/netcal/metrics/Miscalibration.py:444\u001b[0m, in \u001b[0;36m_Miscalibration._prepare_input\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    441\u001b[0m         y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# clip to (0, 1) in order to get all samples into binning scheme\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meps\n\u001b[1;32m    445\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(X, epsilon, \u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m epsilon)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# -------------------------------------------------\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# now evaluate the accuracy/precision\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# on detection mode or binary classification, the accuracy/precision is already given in y\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/numpy/core/getlimits.py:516\u001b[0m, in \u001b[0;36mfinfo.__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    514\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m newdtype\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype, numeric\u001b[38;5;241m.\u001b[39minexact):\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata type \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m not inexact\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (dtype))\n\u001b[1;32m    517\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_finfo_cache\u001b[38;5;241m.\u001b[39mget(dtype)\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: data type <class 'numpy.int64'> not inexact"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import json\n",
    "import hashlib\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, confusion_matrix\n",
    "from netcal.metrics import ECE\n",
    "import sys\n",
    "\n",
    "if 'ipykernel_launcher' in sys.argv[0]:\n",
    "    sys.argv = sys.argv[:1]  # حذف آرگومان‌های ناخواسته\n",
    "\n",
    "# Define paths and read dataset\n",
    "path = '/Users/amir/PycharmProjects/Medfair/MEDFAIR/'\n",
    "demo_data = pd.read_excel(path + 'BrEaST-Lesions-USG-clinical-data-Dec-15-2023.xlsx')\n",
    "images_path = os.path.join(path, '/MEDFAIR/BrEaST-Lesions_USG-images_and_masks/')\n",
    "pathlist = demo_data['Image_filename'].values.tolist()\n",
    "paths = ['/Users/amir/PycharmProjects/Medfair/MEDFAIR/BrEaST-Lesions_USG-images_and_masks/' + i for i in pathlist]\n",
    "demo_data['Path'] = paths\n",
    "\n",
    "# Data preprocessing\n",
    "demo_data = demo_data[~demo_data['Age'].isnull()]\n",
    "age_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "age_labels = ['0-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']\n",
    "demo_data['Age_Category'] = pd.cut(demo_data['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "demo_data['Age_multi'] = demo_data['Age'].values.astype('int')\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(-1, 19), 0, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(20, 39), 1, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(40, 59), 2, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(60, 79), 3, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'] >= 80, 4, demo_data['Age_multi'])\n",
    "\n",
    "demo_data['Age_binary'] = demo_data['Age'].values.astype('int')\n",
    "demo_data['Age_binary'] = np.where(demo_data['Age_binary'].between(-1, 60), 0, demo_data['Age_binary'])\n",
    "demo_data['Age_binary'] = np.where(demo_data['Age_binary'] >= 60, 1, demo_data['Age_binary'])\n",
    "\n",
    "labels = demo_data['Classification'].values.copy()\n",
    "labels[labels == 'malignant'] = '1'\n",
    "labels[labels != '1'] = '0'\n",
    "labels = labels.astype('int')\n",
    "demo_data['binaryLabel'] = labels\n",
    "\n",
    "def split_811(all_meta, patient_ids):\n",
    "    sub_train, sub_val_test = train_test_split(patient_ids, test_size=0.2, random_state=0)\n",
    "    sub_val, sub_test = train_test_split(sub_val_test, test_size=0.5, random_state=0)\n",
    "    train_meta = all_meta[all_meta.CaseID.isin(sub_train)]\n",
    "    val_meta = all_meta[all_meta.CaseID.isin(sub_val)]\n",
    "    test_meta = all_meta[all_meta.CaseID.isin(sub_test)]\n",
    "    return train_meta, val_meta, test_meta\n",
    "\n",
    "sub_train, sub_val, sub_test = split_811(demo_data, np.unique(demo_data['CaseID']))\n",
    "sub_train.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_train.csv')\n",
    "sub_val.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_val.csv')\n",
    "sub_test.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_test.csv')\n",
    "\n",
    "# ایجاد یک نگاشت از دسته‌بندی‌ها به اعداد\n",
    "age_category_mapping = {\n",
    "    '0-10': 0,\n",
    "    '11-20': 1,\n",
    "    '21-30': 2,\n",
    "    '31-40': 3,\n",
    "    '41-50': 4,\n",
    "    '51-60': 5,\n",
    "    '61-70': 6,\n",
    "    '71-80': 7,\n",
    "    '81-90': 8,\n",
    "    '91-100': 9\n",
    "}\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['Path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.dataframe.iloc[idx]['binaryLabel']\n",
    "        protected_attr = self.dataframe.iloc[idx]['Age_Category']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # تبدیل protected_attr به Tensor\n",
    "        protected_attr = torch.tensor(age_category_mapping[protected_attr])\n",
    "\n",
    "        return image, label, protected_attr\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(dataframe=sub_train, transform=transform)\n",
    "val_dataset = CustomDataset(dataframe=sub_val, transform=transform)\n",
    "test_dataset = CustomDataset(dataframe=sub_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the models\n",
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_resnet18.fc.in_features\n",
    "model_resnet18.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_vgg16 = models.vgg16(pretrained=True)\n",
    "num_ftrs = model_vgg16.classifier[6].in_features\n",
    "model_vgg16.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_densenet = models.densenet121(pretrained=True)\n",
    "num_ftrs = model_densenet.classifier.in_features\n",
    "model_densenet.classifier = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "num_ftrs = model_mobilenet.classifier[1].in_features\n",
    "model_mobilenet.classifier[1] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_alexnet = models.alexnet(pretrained=True)\n",
    "num_ftrs = model_alexnet.classifier[6].in_features\n",
    "model_alexnet.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Criterion and optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizers = [optim.SGD(model.parameters(), lr=0.001, momentum=0.9) for model in [model_resnet18, model_vgg16, model_densenet, model_mobilenet, model_alexnet]]\n",
    "\n",
    "def collect_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--experiment', type=str, choices=['baseline', 'CFair', 'LAFTR', 'resampling'])\n",
    "    parser.add_argument('--sensitive_name', default='Age_Category', choices=['Age_Category'])\n",
    "    parser.add_argument('--random_seed', type=int, default=0)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--lr', type=float, default=1e-4)\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
    "    parser.add_argument('--total_epochs', type=int, default=5)\n",
    "    parser.add_argument('--fair_coeff', type=float, default=1.0)\n",
    "    parser.set_defaults(cuda=False)  # Default to False since CUDA is not available\n",
    "    \n",
    "    opt = vars(parser.parse_args())\n",
    "    opt = create_experiment_setting(opt)\n",
    "    return opt\n",
    "\n",
    "def create_experiment_setting(opt):\n",
    "    run_hash = hashlib.sha1()\n",
    "    run_hash.update(str(time.time()).encode('utf-8'))\n",
    "    opt['hash'] = run_hash.hexdigest()[:10]\n",
    "    print('run hash (first 10 digits): ', opt['hash'])\n",
    "    \n",
    "    opt['device'] = torch.device('cuda' if opt['cuda'] and torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    return opt\n",
    "\n",
    "opt = collect_args()\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, opt, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels, protected_attrs in dataloaders[phase]:\n",
    "                inputs = inputs.to(opt['device'])\n",
    "                labels = labels.to(opt['device'])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        if opt['experiment'] == 'CFair':\n",
    "                            fair_loss = compute_fairness_loss(outputs, protected_attrs, opt['fair_coeff'])\n",
    "                            loss += fair_loss\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        print()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the models\n",
    "device = torch.device(\"cpu\")  # Use CPU as CUDA is not available\n",
    "\n",
    "models_list = [model_resnet18, model_vgg16, model_densenet, model_mobilenet, model_alexnet]\n",
    "optimizers = [optim.SGD(model.parameters(), lr=0.001, momentum=0.9) for model in models_list]\n",
    "model_names = ['ResNet18', 'VGG16', 'DenseNet121', 'MobileNetV2', 'AlexNet']\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n",
    "\n",
    "trained_models = []\n",
    "\n",
    "for model, optimizer, model_name in zip(models_list, optimizers, model_names):\n",
    "    model = model.to(device)\n",
    "    print(f\"Training {model_name}...\")\n",
    "    trained_model = train_model(model, dataloaders, criterion, optimizer, opt, num_epochs=10)\n",
    "    trained_models.append(trained_model)\n",
    "    torch.save(trained_model.state_dict(), f'model_{model_name}.pth')\n",
    "    print(f\"{model_name} trained and saved.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb5b0748-397a-4c70-8122-d33d38d27960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         BCE       ECE    TPR@80       TNR       FPR       FNR     EqOdd  \\\n",
      "20  0.666667  0.500000  0.000000  0.666667  0.333333  1.000000  0.666667   \n",
      "21  0.625000  0.400000  0.000000  0.750000  0.250000  1.000000  0.625000   \n",
      "22  0.666667  0.500000  0.666667  0.000000  1.000000  0.333333  0.666667   \n",
      "23  0.250000  0.166667  0.500000  1.000000  0.000000  0.500000  0.250000   \n",
      "24  0.250000  0.333333  0.500000  1.000000  0.000000  0.500000  0.250000   \n",
      "\n",
      "      Model   Group  \n",
      "20  AlexNet  Grp. 3  \n",
      "21  AlexNet  Grp. 4  \n",
      "22  AlexNet  Grp. 5  \n",
      "23  AlexNet  Grp. 6  \n",
      "24  AlexNet  Grp. 7  \n"
     ]
    }
   ],
   "source": [
    "# Define evaluation functions\n",
    "def calculate_fairness_metrics(y_true, y_pred, sensitive_attr):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    FPR = fp / (fp + tn)\n",
    "    FNR = fn / (fn + tp)\n",
    "    TPR = tp / (tp + fn)\n",
    "    TNR = tn / (tn + fp)\n",
    "    PR80_TNR = TPR / TNR if TNR != 0 else np.inf\n",
    "    \n",
    "    BCE = (FPR + FNR) / 2\n",
    "\n",
    "    ece = ECE().measure(y_pred.astype(float), y_true)\n",
    "    \n",
    "    # Balanced Equalized Odds (BEO) calculation\n",
    "    groups = np.unique(sensitive_attr)\n",
    "    TPR_diff = []\n",
    "    FPR_diff = []\n",
    "    for group in groups:\n",
    "        group_idx = (sensitive_attr == group)\n",
    "        group_y_true = y_true[group_idx]\n",
    "        group_y_pred = y_pred[group_idx]\n",
    "        cm_group = confusion_matrix(group_y_true, group_y_pred)\n",
    "        tn_g, fp_g, fn_g, tp_g = cm_group.ravel()\n",
    "\n",
    "        FPR_g = fp_g / (fp_g + tn_g) if (fp_g + tn_g) > 0 else 0\n",
    "        TPR_g = tp_g / (tp_g + fn_g) if (tp_g + fn_g) > 0 else 0\n",
    "\n",
    "        FPR_diff.append(FPR_g)\n",
    "        TPR_diff.append(TPR_g)\n",
    "    \n",
    "    FPR_diff = np.abs(np.diff(FPR_diff)).sum() / (len(groups) - 1)\n",
    "    TPR_diff = np.abs(np.diff(TPR_diff)).sum() / (len(groups) - 1)\n",
    "\n",
    "    Balanced_EO = (FPR_diff + TPR_diff) / 2\n",
    "    \n",
    "    metrics = {\n",
    "        \"BCE\": BCE,\n",
    "        \"ECE\": ece,\n",
    "        \"FPR\": FPR,\n",
    "        \"FNR\": FNR,\n",
    "        \"PR80_TNR\": PR80_TNR,\n",
    "        \"Balanced_EO\": Balanced_EO\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def expected_calibration_error(y_true, y_pred):\n",
    "    y_pred = y_pred.astype(np.float32)\n",
    "    ece = ECE()\n",
    "    return ece.measure(y_pred, y_true)\n",
    "\n",
    "def false_positive_rate(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, _, _ = cm.ravel()\n",
    "    return fp / (fp + tn)\n",
    "\n",
    "def false_negative_rate(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    _, _, fn, tp = cm.ravel()\n",
    "    return fn / (fn + tp)\n",
    "\n",
    "def pr_at_tnr(y_true, y_pred, threshold=0.8):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    idx = np.argmax(fpr >= threshold)\n",
    "    return tpr[idx]\n",
    "\n",
    "def balanced_equalized_odds(y_true, y_pred, protected_attrs):\n",
    "    groups = np.unique(protected_attrs)\n",
    "    fpr_diff = []\n",
    "    fnr_diff = []\n",
    "    \n",
    "    for group in groups:\n",
    "        group_idx = (protected_attrs == group)\n",
    "        group_y_true = y_true[group_idx]\n",
    "        group_y_pred = y_pred[group_idx]\n",
    "        \n",
    "        fpr_diff.append(false_positive_rate(group_y_true, group_y_pred))\n",
    "        fnr_diff.append(false_negative_rate(group_y_true, group_y_pred))\n",
    "    \n",
    "    fpr_diff = np.abs(np.diff(fpr_diff)).sum() / (len(groups) - 1)\n",
    "    fnr_diff = np.abs(np.diff(fnr_diff)).sum() / (len(groups) - 1)\n",
    "    \n",
    "    return (fpr_diff + fnr_diff) / 2\n",
    "\n",
    "# ارزیابی مدل‌ها و محاسبه متریک‌ها\n",
    "def evaluate_model(model, test_loader, opt):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_protected_attrs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, protected_attrs in test_loader:\n",
    "            inputs = inputs.to(opt['device'])\n",
    "            labels = labels.to(opt['device'])\n",
    "\n",
    "            preds = model(inputs)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "            all_protected_attrs.extend(protected_attrs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_protected_attrs = np.array(all_protected_attrs)\n",
    "\n",
    "    metrics = {}\n",
    "    for group in np.unique(all_protected_attrs):\n",
    "        group_idx = all_protected_attrs == group\n",
    "        y_true = all_labels[group_idx]\n",
    "        y_pred = all_preds[group_idx]\n",
    "\n",
    "        if len(y_true) == 0:\n",
    "            continue  # پرش از گروه‌هایی که داده‌ای ندارند\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "        FPR = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        FNR = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        TPR = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        TNR = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "        metrics[group] = {\n",
    "            'BCE': (FPR + FNR) / 2,\n",
    "            'ECE': ECE().measure(y_pred.astype(float), y_true),\n",
    "            'TPR@80': TPR,\n",
    "            'TNR': TNR,\n",
    "            'FPR': FPR,\n",
    "            'FNR': FNR,\n",
    "            'EqOdd': (FPR + FNR) / 2\n",
    "        }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# مدل‌ها را ارزیابی کنید و نتایج را در قالب یک DataFrame قرار دهید\n",
    "# مدل‌ها را ارزیابی کنید و نتایج را در قالب یک DataFrame قرار دهید\n",
    "final_results = pd.DataFrame()\n",
    "\n",
    "for model_name, model in zip(model_names, trained_models):\n",
    "    fairness_metrics = evaluate_model(model, test_loader, opt)\n",
    "    for group, metrics in fairness_metrics.items():\n",
    "        metrics['Model'] = model_name\n",
    "        metrics['Group'] = f'Grp. {group}'\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        final_results = pd.concat([final_results, metrics_df], ignore_index=True)\n",
    "\n",
    "# مرتب‌سازی نتایج بر اساس Model و Group\n",
    "final_results = final_results.sort_values(by=['Model', 'Group'])\n",
    "\n",
    "# نمایش نتایج نهایی\n",
    "print(final_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dce6834-67a1-4584-a035-f97d33296dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ResNet18...\n",
      "Evaluating VGG16...\n",
      "Evaluating DenseNet121...\n",
      "Evaluating MobileNetV2...\n",
      "Evaluating AlexNet...\n",
      "         BCE           ECE    TPR@80       TNR       FPR       FNR     EqOdd  \\\n",
      "20  0.666667  5.000000e-01  0.000000  0.666667  0.333333  1.000000  0.666667   \n",
      "21  0.625000  4.000000e-01  0.000000  0.750000  0.250000  1.000000  0.625000   \n",
      "22  0.666667  5.000000e-01  0.666667  0.000000  1.000000  0.333333  0.666667   \n",
      "23  0.250000  1.666667e-01  0.500000  1.000000  0.000000  0.500000  0.250000   \n",
      "24  0.250000  3.333333e-01  0.500000  1.000000  0.000000  0.500000  0.250000   \n",
      "10  0.500000  2.500000e-01  0.000000  1.000000  0.000000  1.000000  0.500000   \n",
      "11  0.500000  2.000000e-01  0.000000  1.000000  0.000000  1.000000  0.500000   \n",
      "12  0.166667  2.500000e-01  0.666667  1.000000  0.000000  0.333333  0.166667   \n",
      "13  0.500000  5.000000e-01  0.500000  0.500000  0.500000  0.500000  0.500000   \n",
      "14  0.250000  3.333333e-01  0.500000  1.000000  0.000000  0.500000  0.250000   \n",
      "15  0.833333  7.500000e-01  0.000000  0.333333  0.666667  1.000000  0.833333   \n",
      "16  0.625000  4.000000e-01  0.000000  0.750000  0.250000  1.000000  0.625000   \n",
      "17  1.000000  1.000000e+00  0.000000  0.000000  1.000000  1.000000  1.000000   \n",
      "18  0.500000  3.333333e-01  0.000000  1.000000  0.000000  1.000000  0.500000   \n",
      "19  0.000000  2.220446e-16  1.000000  1.000000  0.000000  0.000000  0.000000   \n",
      "0   0.666667  5.000000e-01  0.000000  0.666667  0.333333  1.000000  0.666667   \n",
      "1   0.625000  4.000000e-01  0.000000  0.750000  0.250000  1.000000  0.625000   \n",
      "2   0.166667  2.500000e-01  0.666667  1.000000  0.000000  0.333333  0.166667   \n",
      "3   0.250000  3.333333e-01  1.000000  0.500000  0.500000  0.000000  0.250000   \n",
      "4   0.500000  3.333333e-01  1.000000  0.000000  1.000000  0.000000  0.500000   \n",
      "5   0.500000  2.500000e-01  0.000000  1.000000  0.000000  1.000000  0.500000   \n",
      "6   0.500000  2.000000e-01  0.000000  1.000000  0.000000  1.000000  0.500000   \n",
      "7   0.500000  7.500000e-01  0.000000  1.000000  0.000000  1.000000  0.500000   \n",
      "8   0.500000  3.333333e-01  0.000000  1.000000  0.000000  1.000000  0.500000   \n",
      "9   0.500000  6.666667e-01  0.000000  1.000000  0.000000  1.000000  0.500000   \n",
      "\n",
      "          Model   Group  \n",
      "20      AlexNet  Grp. 3  \n",
      "21      AlexNet  Grp. 4  \n",
      "22      AlexNet  Grp. 5  \n",
      "23      AlexNet  Grp. 6  \n",
      "24      AlexNet  Grp. 7  \n",
      "10  DenseNet121  Grp. 3  \n",
      "11  DenseNet121  Grp. 4  \n",
      "12  DenseNet121  Grp. 5  \n",
      "13  DenseNet121  Grp. 6  \n",
      "14  DenseNet121  Grp. 7  \n",
      "15  MobileNetV2  Grp. 3  \n",
      "16  MobileNetV2  Grp. 4  \n",
      "17  MobileNetV2  Grp. 5  \n",
      "18  MobileNetV2  Grp. 6  \n",
      "19  MobileNetV2  Grp. 7  \n",
      "0      ResNet18  Grp. 3  \n",
      "1      ResNet18  Grp. 4  \n",
      "2      ResNet18  Grp. 5  \n",
      "3      ResNet18  Grp. 6  \n",
      "4      ResNet18  Grp. 7  \n",
      "5         VGG16  Grp. 3  \n",
      "6         VGG16  Grp. 4  \n",
      "7         VGG16  Grp. 5  \n",
      "8         VGG16  Grp. 6  \n",
      "9         VGG16  Grp. 7  \n"
     ]
    }
   ],
   "source": [
    "# مدل‌ها را ارزیابی کنید و نتایج را در قالب یک DataFrame قرار دهید\n",
    "final_results = pd.DataFrame()\n",
    "\n",
    "for model_name, model in zip(model_names, trained_models):\n",
    "    print(f\"Evaluating {model_name}...\")  # اضافه کردن چاپ برای بررسی\n",
    "    fairness_metrics = evaluate_model(model, test_loader, opt)\n",
    "    for group, metrics in fairness_metrics.items():\n",
    "        metrics['Model'] = model_name\n",
    "        metrics['Group'] = f'Grp. {group}'\n",
    "        metrics_df = pd.DataFrame([metrics])\n",
    "        final_results = pd.concat([final_results, metrics_df], ignore_index=True)\n",
    "\n",
    "# مرتب‌سازی نتایج بر اساس Model و Group\n",
    "final_results = final_results.sort_values(by=['Model', 'Group'])\n",
    "\n",
    "# نمایش نتایج نهایی\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f5a4c-cef2-440b-aaf4-e95e9aaae5e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
