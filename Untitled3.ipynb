{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c371bd15-2cd6-4ab8-a80d-af50136ac137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537, 485, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/amir/Documents/Projects/Python/Medfair/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet18...\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7270 Acc: 0.5556\n",
      "val Loss: 0.7462 Acc: 0.5714\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.5793 Acc: 0.7368\n",
      "val Loss: 0.6978 Acc: 0.6190\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.4330 Acc: 0.8889\n",
      "val Loss: 0.6114 Acc: 0.6190\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3682 Acc: 0.8947\n",
      "val Loss: 0.5903 Acc: 0.6667\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.2754 Acc: 0.9357\n",
      "val Loss: 0.5465 Acc: 0.6667\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2323 Acc: 0.9415\n",
      "val Loss: 0.4842 Acc: 0.7619\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.1492 Acc: 0.9883\n",
      "val Loss: 0.5413 Acc: 0.7143\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0988 Acc: 0.9942\n",
      "val Loss: 0.4982 Acc: 0.7143\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0878 Acc: 0.9883\n",
      "val Loss: 0.5148 Acc: 0.7143\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0547 Acc: 1.0000\n",
      "val Loss: 0.5063 Acc: 0.7143\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0490 Acc: 1.0000\n",
      "val Loss: 0.5159 Acc: 0.7619\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0476 Acc: 1.0000\n",
      "val Loss: 0.4954 Acc: 0.8571\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0391 Acc: 1.0000\n",
      "val Loss: 0.5042 Acc: 0.7619\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0236 Acc: 1.0000\n",
      "val Loss: 0.5267 Acc: 0.7143\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0290 Acc: 1.0000\n",
      "val Loss: 0.5131 Acc: 0.7143\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0163 Acc: 1.0000\n",
      "val Loss: 0.5068 Acc: 0.8571\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0178 Acc: 1.0000\n",
      "val Loss: 0.5172 Acc: 0.8095\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0135 Acc: 1.0000\n",
      "val Loss: 0.5656 Acc: 0.6667\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0110 Acc: 1.0000\n",
      "val Loss: 0.5659 Acc: 0.6667\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0132 Acc: 1.0000\n",
      "val Loss: 0.5222 Acc: 0.7143\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0093 Acc: 1.0000\n",
      "val Loss: 0.5180 Acc: 0.8095\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0109 Acc: 1.0000\n",
      "val Loss: 0.4960 Acc: 0.8095\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0102 Acc: 1.0000\n",
      "val Loss: 0.4822 Acc: 0.7619\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0111 Acc: 1.0000\n",
      "val Loss: 0.4915 Acc: 0.8095\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0087 Acc: 1.0000\n",
      "val Loss: 0.4991 Acc: 0.7619\n",
      "\n",
      "ResNet18 trained and saved.\n",
      "Training VGG16...\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7209 Acc: 0.5322\n",
      "val Loss: 0.6928 Acc: 0.5714\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.6804 Acc: 0.6374\n",
      "val Loss: 0.6117 Acc: 0.6190\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5877 Acc: 0.6608\n",
      "val Loss: 0.6260 Acc: 0.5238\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.5303 Acc: 0.7427\n",
      "val Loss: 0.5675 Acc: 0.6190\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4845 Acc: 0.7544\n",
      "val Loss: 0.5368 Acc: 0.7143\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4243 Acc: 0.7895\n",
      "val Loss: 0.5217 Acc: 0.7619\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3727 Acc: 0.8421\n",
      "val Loss: 0.5237 Acc: 0.7619\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.2773 Acc: 0.9123\n",
      "val Loss: 0.5558 Acc: 0.6190\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.2835 Acc: 0.8713\n",
      "val Loss: 0.7245 Acc: 0.6667\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.1624 Acc: 0.9591\n",
      "val Loss: 0.8289 Acc: 0.6667\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.1163 Acc: 0.9708\n",
      "val Loss: 0.6621 Acc: 0.7143\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0609 Acc: 0.9883\n",
      "val Loss: 0.8616 Acc: 0.6667\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0392 Acc: 0.9883\n",
      "val Loss: 0.8716 Acc: 0.6667\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0463 Acc: 0.9883\n",
      "val Loss: 1.0835 Acc: 0.6190\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0777 Acc: 0.9708\n",
      "val Loss: 1.0837 Acc: 0.6190\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0423 Acc: 0.9883\n",
      "val Loss: 1.2178 Acc: 0.6190\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0400 Acc: 0.9825\n",
      "val Loss: 1.3018 Acc: 0.7143\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0152 Acc: 0.9942\n",
      "val Loss: 1.2014 Acc: 0.7143\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0149 Acc: 1.0000\n",
      "val Loss: 1.2481 Acc: 0.7143\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0071 Acc: 1.0000\n",
      "val Loss: 1.3570 Acc: 0.6190\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0036 Acc: 1.0000\n",
      "val Loss: 1.4578 Acc: 0.6667\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0019 Acc: 1.0000\n",
      "val Loss: 1.4956 Acc: 0.7143\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0013 Acc: 1.0000\n",
      "val Loss: 1.5885 Acc: 0.7143\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0024 Acc: 1.0000\n",
      "val Loss: 1.5079 Acc: 0.7143\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0014 Acc: 1.0000\n",
      "val Loss: 1.6384 Acc: 0.6190\n",
      "\n",
      "VGG16 trained and saved.\n",
      "Training DenseNet121...\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7288 Acc: 0.4971\n",
      "val Loss: 0.7918 Acc: 0.5714\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.6257\n",
      "val Loss: 0.6815 Acc: 0.4762\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5342 Acc: 0.8246\n",
      "val Loss: 0.7030 Acc: 0.5238\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4296 Acc: 0.7661\n",
      "val Loss: 0.6911 Acc: 0.5238\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.4050 Acc: 0.8596\n",
      "val Loss: 0.6771 Acc: 0.4762\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2446 Acc: 0.9766\n",
      "val Loss: 0.8342 Acc: 0.5714\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2119 Acc: 0.9474\n",
      "val Loss: 0.7141 Acc: 0.5238\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1298 Acc: 0.9942\n",
      "val Loss: 0.6138 Acc: 0.6190\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0943 Acc: 1.0000\n",
      "val Loss: 0.6444 Acc: 0.5714\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0806 Acc: 0.9942\n",
      "val Loss: 0.7374 Acc: 0.5238\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0538 Acc: 1.0000\n",
      "val Loss: 0.7080 Acc: 0.6190\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0362 Acc: 1.0000\n",
      "val Loss: 0.6649 Acc: 0.6667\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0452 Acc: 1.0000\n",
      "val Loss: 0.6249 Acc: 0.7143\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0297 Acc: 1.0000\n",
      "val Loss: 0.7171 Acc: 0.6190\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 1.0000\n",
      "val Loss: 0.8688 Acc: 0.5238\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0260 Acc: 0.9942\n",
      "val Loss: 0.8866 Acc: 0.5238\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0189 Acc: 1.0000\n",
      "val Loss: 0.7297 Acc: 0.6190\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0181 Acc: 1.0000\n",
      "val Loss: 0.6674 Acc: 0.6667\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 1.0000\n",
      "val Loss: 0.6674 Acc: 0.6667\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0234 Acc: 0.9942\n",
      "val Loss: 0.6515 Acc: 0.6667\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0151 Acc: 1.0000\n",
      "val Loss: 0.7735 Acc: 0.6190\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0482 Acc: 0.9942\n",
      "val Loss: 0.9010 Acc: 0.5714\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0366 Acc: 0.9942\n",
      "val Loss: 0.8158 Acc: 0.5714\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0196 Acc: 1.0000\n",
      "val Loss: 0.8826 Acc: 0.6190\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0149 Acc: 1.0000\n",
      "val Loss: 0.9514 Acc: 0.5714\n",
      "\n",
      "DenseNet121 trained and saved.\n",
      "Training MobileNetV2...\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.7053 Acc: 0.5673\n",
      "val Loss: 0.6944 Acc: 0.5238\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.6671 Acc: 0.6140\n",
      "val Loss: 0.6267 Acc: 0.6667\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5237 Acc: 0.7895\n",
      "val Loss: 0.5507 Acc: 0.8571\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.4412 Acc: 0.8713\n",
      "val Loss: 0.5229 Acc: 0.8571\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3726 Acc: 0.8947\n",
      "val Loss: 0.5285 Acc: 0.7143\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.2933 Acc: 0.9415\n",
      "val Loss: 0.5162 Acc: 0.7619\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.2296 Acc: 0.9825\n",
      "val Loss: 0.4734 Acc: 0.7619\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.1861 Acc: 0.9591\n",
      "val Loss: 0.4168 Acc: 0.8571\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.1445 Acc: 0.9708\n",
      "val Loss: 0.4333 Acc: 0.7619\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0877 Acc: 0.9942\n",
      "val Loss: 0.5188 Acc: 0.8095\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0898 Acc: 0.9883\n",
      "val Loss: 0.4497 Acc: 0.7619\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0699 Acc: 0.9942\n",
      "val Loss: 0.4458 Acc: 0.7619\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0385 Acc: 0.9942\n",
      "val Loss: 0.5139 Acc: 0.7619\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 1.0000\n",
      "val Loss: 0.5456 Acc: 0.7619\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0194 Acc: 1.0000\n",
      "val Loss: 0.5305 Acc: 0.8095\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0209 Acc: 1.0000\n",
      "val Loss: 0.5125 Acc: 0.8571\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0183 Acc: 1.0000\n",
      "val Loss: 0.5078 Acc: 0.7619\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0136 Acc: 1.0000\n",
      "val Loss: 0.4997 Acc: 0.8095\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0150 Acc: 1.0000\n",
      "val Loss: 0.4882 Acc: 0.7619\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0247 Acc: 0.9942\n",
      "val Loss: 0.5186 Acc: 0.8095\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0131 Acc: 1.0000\n",
      "val Loss: 0.6621 Acc: 0.8095\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0143 Acc: 1.0000\n",
      "val Loss: 0.6125 Acc: 0.8095\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0345 Acc: 0.9883\n",
      "val Loss: 0.6191 Acc: 0.7619\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0104 Acc: 1.0000\n",
      "val Loss: 0.6470 Acc: 0.7143\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0275 Acc: 0.9942\n",
      "val Loss: 0.6094 Acc: 0.7143\n",
      "\n",
      "MobileNetV2 trained and saved.\n",
      "Training AlexNet...\n",
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6829 Acc: 0.5848\n",
      "val Loss: 0.6505 Acc: 0.5714\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.7244 Acc: 0.6257\n",
      "val Loss: 0.6715 Acc: 0.5714\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.7064 Acc: 0.5614\n",
      "val Loss: 0.7723 Acc: 0.5714\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.6383 Acc: 0.6257\n",
      "val Loss: 0.6793 Acc: 0.5238\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.5201 Acc: 0.7836\n",
      "val Loss: 0.6228 Acc: 0.6667\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.4433 Acc: 0.7719\n",
      "val Loss: 0.6813 Acc: 0.6190\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3902 Acc: 0.7778\n",
      "val Loss: 0.5996 Acc: 0.6667\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3760 Acc: 0.8304\n",
      "val Loss: 0.9381 Acc: 0.5714\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3556 Acc: 0.8363\n",
      "val Loss: 0.6273 Acc: 0.6667\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.2560 Acc: 0.8830\n",
      "val Loss: 0.6123 Acc: 0.6667\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.2211 Acc: 0.9064\n",
      "val Loss: 0.6212 Acc: 0.8095\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.2000 Acc: 0.9064\n",
      "val Loss: 0.7141 Acc: 0.6667\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.1780 Acc: 0.9240\n",
      "val Loss: 0.9418 Acc: 0.5238\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.1743 Acc: 0.9357\n",
      "val Loss: 0.6610 Acc: 0.6667\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.1263 Acc: 0.9474\n",
      "val Loss: 0.5814 Acc: 0.7143\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.1087 Acc: 0.9591\n",
      "val Loss: 0.7370 Acc: 0.6667\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0776 Acc: 0.9708\n",
      "val Loss: 0.7876 Acc: 0.5714\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0543 Acc: 0.9883\n",
      "val Loss: 1.0262 Acc: 0.6190\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0467 Acc: 0.9883\n",
      "val Loss: 0.9837 Acc: 0.7143\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0345 Acc: 0.9942\n",
      "val Loss: 0.9853 Acc: 0.7143\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0298 Acc: 0.9942\n",
      "val Loss: 1.1455 Acc: 0.6190\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0196 Acc: 1.0000\n",
      "val Loss: 1.1323 Acc: 0.6190\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0184 Acc: 1.0000\n",
      "val Loss: 1.1327 Acc: 0.6667\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0177 Acc: 1.0000\n",
      "val Loss: 1.2007 Acc: 0.7143\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0133 Acc: 1.0000\n",
      "val Loss: 1.1675 Acc: 0.6667\n",
      "\n",
      "AlexNet trained and saved.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 270\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mprint\u001b[39m(eo_df)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model, model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(trained_models, model_names):\n\u001b[0;32m--> 270\u001b[0m     accuracy, f1, age_group_accuracies, age_group_f1_scores, dp, eo \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotected_attr_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAge_Category\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     print_fairness_metrics(model_name, accuracy, f1, age_group_accuracies, age_group_f1_scores, dp, eo)\n",
      "Cell \u001b[0;32mIn[1], line 227\u001b[0m, in \u001b[0;36mevaluate_bias\u001b[0;34m(model, dataloader, protected_attr_name)\u001b[0m\n\u001b[1;32m    224\u001b[0m all_protected_attrs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_protected_attrs)\n\u001b[1;32m    226\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(all_preds \u001b[38;5;241m==\u001b[39m all_labels)\n\u001b[0;32m--> 227\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m(all_labels, all_preds, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    229\u001b[0m dp \u001b[38;5;241m=\u001b[39m demographic_parity(all_labels, all_preds, all_protected_attrs)\n\u001b[1;32m    230\u001b[0m eo \u001b[38;5;241m=\u001b[39m equalized_odds(all_labels, all_preds, all_protected_attrs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_score' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Additional imports for deep learning models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "# Add bias removal techniques from Beta\n",
    "import argparse\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "\n",
    "# read dateset\n",
    "path = '/Users/amir/PycharmProjects/Medfair/MEDFAIR/'\n",
    "\n",
    "demo_data = pd.read_excel(path + 'BrEaST-Lesions-USG-clinical-data-Dec-15-2023.xlsx')\n",
    "\n",
    "images_path = os.path.join(path, '/MEDFAIR/BrEaST-Lesions_USG-images_and_masks/')\n",
    "\n",
    "\n",
    "demo_data\n",
    "# add image path to the metadata\n",
    "pathlist = demo_data['Image_filename'].values.tolist()\n",
    "paths = ['/Users/amir/PycharmProjects/Medfair/MEDFAIR/BrEaST-Lesions_USG-images_and_masks/' + i for i in pathlist]\n",
    "demo_data['Path'] = paths\n",
    "# remove age/sex == null \n",
    "demo_data = demo_data[~demo_data['Age'].isnull()]\n",
    "demo_data\n",
    "# Grouping ages by decades\n",
    "age_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "age_labels = ['0-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']\n",
    "\n",
    "# Assign age categories to the 'Age' column\n",
    "demo_data['Age_Category'] = pd.cut(demo_data['Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "demo_data\n",
    "# split subjects to different age groups\n",
    "demo_data['Age_multi'] = demo_data['Age'].values.astype('int')\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(-1,19), 0, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(20,39), 1, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(40,59), 2, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi'].between(60,79), 3, demo_data['Age_multi'])\n",
    "demo_data['Age_multi'] = np.where(demo_data['Age_multi']>=80, 4, demo_data['Age_multi'])\n",
    "\n",
    "demo_data['Age_binary'] = demo_data['Age'].values.astype('int')\n",
    "demo_data['Age_binary'] = np.where(demo_data['Age_binary'].between(-1, 60), 0, demo_data['Age_binary'])\n",
    "demo_data['Age_binary'] = np.where(demo_data['Age_binary']>= 60, 1, demo_data['Age_binary'])\n",
    "demo_data\n",
    "# convert to binary labels\n",
    "labels = demo_data['Classification'].values.copy()\n",
    "labels[labels == 'malignant'] = '1'\n",
    "labels[labels != '1'] = '0'\n",
    "\n",
    "labels = labels.astype('int')\n",
    "\n",
    "demo_data['binaryLabel'] = labels\n",
    "demo_data\n",
    "def split_811(all_meta, patient_ids):\n",
    "    sub_train, sub_val_test = train_test_split(patient_ids, test_size=0.2, random_state=0)\n",
    "    sub_val, sub_test = train_test_split(sub_val_test, test_size=0.5, random_state=0)\n",
    "    train_meta = all_meta[all_meta.CaseID.isin(sub_train)]\n",
    "    val_meta = all_meta[all_meta.CaseID.isin(sub_val)]\n",
    "    test_meta = all_meta[all_meta.CaseID.isin(sub_test)]\n",
    "    return train_meta, val_meta, test_meta\n",
    "\n",
    "sub_train, sub_val, sub_test = split_811(demo_data, np.unique(demo_data['CaseID']))\n",
    "sub_train.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_train.csv')\n",
    "sub_val.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_val.csv')\n",
    "sub_test.to_csv('/Users/amir/PycharmProjects/Medfair/MEDFAIR/split/new_test.csv')\n",
    "# you can have a look of some examples here\n",
    "img = cv2.imread('/Users/amir/PycharmProjects/Medfair/MEDFAIR/BrEaST-Lesions_USG-images_and_masks/case001_tumor.png')\n",
    "print(img.shape)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['Path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.dataframe.iloc[idx]['binaryLabel']\n",
    "        protected_attr = self.dataframe.iloc[idx]['Age_Category']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, protected_attr\n",
    "# Define data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomDataset(dataframe=sub_train, transform=transform)\n",
    "val_dataset = CustomDataset(dataframe=sub_val, transform=transform)\n",
    "test_dataset = CustomDataset(dataframe=sub_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the models\n",
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_resnet18.fc.in_features\n",
    "model_resnet18.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_vgg16 = models.vgg16(pretrained=True)\n",
    "num_ftrs = model_vgg16.classifier[6].in_features\n",
    "model_vgg16.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_densenet = models.densenet121(pretrained=True)\n",
    "num_ftrs = model_densenet.classifier.in_features\n",
    "model_densenet.classifier = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "num_ftrs = model_mobilenet.classifier[1].in_features\n",
    "model_mobilenet.classifier[1] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_alexnet = models.alexnet(pretrained=True)\n",
    "num_ftrs = model_alexnet.classifier[6].in_features\n",
    "model_alexnet.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Criterion and optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizers = [\n",
    "    optim.SGD(model_resnet18.parameters(), lr=0.001, momentum=0.9),\n",
    "    optim.SGD(model_vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "]\n",
    "\n",
    "# Collect arguments for bias removal\n",
    "def collect_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Add other arguments as required\n",
    "    parser.add_argument('--experiment', type=str, choices=['baseline', 'CFair', 'LAFTR', 'resampling'])\n",
    "    parser.add_argument('--sensitive_name', default='Age_Category', choices=['Age_Category'])\n",
    "    parser.add_argument('--random_seed', type=int, default=0)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--lr', type=float, default=1e-4)\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
    "    parser.add_argument('--total_epochs', type=int, default=25)\n",
    "    parser.add_argument('--fair_coeff', type=float, default=1.0)\n",
    "    parser.set_defaults(cuda=True)\n",
    "    \n",
    "    opt = vars(parser.parse_args())\n",
    "    opt = create_experiment_setting(opt)\n",
    "    return opt\n",
    "\n",
    "def create_experiment_setting(opt):\n",
    "    run_hash = hashlib.sha1()\n",
    "    run_hash.update(str(time.time()).encode('utf-8'))\n",
    "    opt['hash'] = run_hash.hexdigest()[:10]\n",
    "    print('run hash (first 10 digits): ', opt['hash'])\n",
    "    \n",
    "    opt['device'] = torch.device('cuda' if opt['cuda'] else 'cpu')\n",
    "    \n",
    "    return opt\n",
    "\n",
    "\n",
    "# Train the models with bias removal techniques\n",
    "def train_model(model, dataloaders, criterion, optimizer, opt, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels, protected_attrs in dataloaders[phase]:\n",
    "                inputs = inputs.to(opt['device'])\n",
    "                labels = labels.to(opt['device'])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        if opt['experiment'] == 'CFair':\n",
    "                            fair_loss = compute_fairness_loss(outputs, protected_attrs, opt['fair_coeff'])\n",
    "                            loss += fair_loss\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        print()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the models\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "models_list = [model_resnet18, model_vgg16, model_densenet, model_mobilenet, model_alexnet]\n",
    "optimizers = [optim.SGD(model.parameters(), lr=0.001, momentum=0.9) for model in models_list]\n",
    "model_names = ['ResNet18', 'VGG16', 'DenseNet121', 'MobileNetV2', 'AlexNet']\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n",
    "\n",
    "trained_models = []\n",
    "\n",
    "for model, optimizer, model_name in zip(models_list, optimizers, model_names):\n",
    "    model = model.to(device)\n",
    "    print(f\"Training {model_name}...\")\n",
    "    trained_model = train_model(model, dataloaders, criterion, optimizer, num_epochs=25)\n",
    "    trained_models.append(trained_model)\n",
    "    torch.save(trained_model.state_dict(), f'model_{model_name}.pth')\n",
    "    print(f\"{model_name} trained and saved.\")\n",
    "\n",
    "# Evaluate bias in the models\n",
    "def evaluate_bias(model, dataloader, opt):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_protected_attrs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs = data[0].to(opt['device'])\n",
    "            labels = data[1].to(opt['device'])\n",
    "            protected_attrs = data[2]\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_protected_attrs.extend(protected_attrs)\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_protected_attrs = np.array(all_protected_attrs)\n",
    "\n",
    "    accuracy = np.mean(all_preds == all_labels)\n",
    "    dp = demographic_parity(all_labels, all_preds, all_protected_attrs)\n",
    "    eo = equalized_odds(all_labels, all_preds, all_protected_attrs)\n",
    "\n",
    "    return accuracy, dp, eo\n",
    "\n",
    "def print_fairness_metrics(model_name, accuracy, dp, eo):\n",
    "    print(f\"\\n=== Fairness Metrics for {model_name} ===\")\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nDemographic Parity:\")\n",
    "    dp_df = pd.DataFrame.from_dict(dp, orient='index', columns=['Demographic Parity'])\n",
    "    print(dp_df)\n",
    "    print(\"\\nEqualized Odds:\")\n",
    "    eo_df = pd.DataFrame.from_dict(eo, orient='index')\n",
    "    print(eo_df)\n",
    "\n",
    "def print_fairness_metrics(model_name, accuracy, f1, age_group_accuracies, age_group_f1_scores, dp, eo):\n",
    "    print(f\"\\n=== Fairness Metrics for {model_name} ===\")\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Overall F1-Score: {f1:.4f}\")\n",
    "\n",
    "    print(\"\\nAccuracy by Age Group:\")\n",
    "    for age_group, group_accuracy in age_group_accuracies.items():\n",
    "        print(f\"  Age group {age_group}: {group_accuracy:.4f}\")\n",
    "\n",
    "    print(\"\\nF1-Score by Age Group:\")\n",
    "    for age_group, group_f1 in age_group_f1_scores.items():\n",
    "        print(f\"  Age group {age_group}: {group_f1:.4f}\")\n",
    "\n",
    "    print(\"\\nDemographic Parity:\")\n",
    "    dp_df = pd.DataFrame.from_dict(dp, orient='index', columns=['Demographic Parity'])\n",
    "    print(dp_df)\n",
    "\n",
    "    print(\"\\nEqualized Odds:\")\n",
    "    eo_df = pd.DataFrame.from_dict(eo, orient='index')\n",
    "    print(eo_df)\n",
    "\n",
    "for model, model_name in zip(trained_models, model_names):\n",
    "    accuracy, f1, age_group_accuracies, age_group_f1_scores, dp, eo = evaluate_bias(model, test_loader, protected_attr_name='Age_Category')\n",
    "    print_fairness_metrics(model_name, accuracy, f1, age_group_accuracies, age_group_f1_scores, dp, eo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3397fc3-5941-410a-8b76-78650629084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fairness Metrics for ResNet18 ===\n",
      "Overall Accuracy: 0.8636\n",
      "Overall F1-Score: 0.8571\n",
      "\n",
      "Accuracy by Age Group:\n",
      "  Age group 31-40: 1.0000\n",
      "  Age group 41-50: 0.8000\n",
      "  Age group 51-60: 1.0000\n",
      "  Age group 61-70: 0.8333\n",
      "  Age group 71-80: 0.6667\n",
      "\n",
      "F1-Score by Age Group:\n",
      "  Age group 31-40: 1.0000\n",
      "  Age group 41-50: 0.7111\n",
      "  Age group 51-60: 1.0000\n",
      "  Age group 61-70: 0.8148\n",
      "  Age group 71-80: 0.6667\n",
      "\n",
      "Demographic Parity:\n",
      "       Demographic Parity\n",
      "31-40            0.250000\n",
      "41-50            0.000000\n",
      "51-60            0.750000\n",
      "61-70            0.166667\n",
      "71-80            0.333333\n",
      "\n",
      "Equalized Odds:\n",
      "       TPR  FPR\n",
      "31-40  1.0  0.0\n",
      "41-50  0.0  0.0\n",
      "51-60  1.0  0.0\n",
      "61-70  0.5  0.0\n",
      "71-80  0.5  0.0\n",
      "\n",
      "=== Fairness Metrics for VGG16 ===\n",
      "Overall Accuracy: 0.6818\n",
      "Overall F1-Score: 0.6463\n",
      "\n",
      "Accuracy by Age Group:\n",
      "  Age group 31-40: 0.5000\n",
      "  Age group 41-50: 0.8000\n",
      "  Age group 51-60: 0.5000\n",
      "  Age group 61-70: 0.8333\n",
      "  Age group 71-80: 0.6667\n",
      "\n",
      "F1-Score by Age Group:\n",
      "  Age group 31-40: 0.5000\n",
      "  Age group 41-50: 0.7111\n",
      "  Age group 51-60: 0.5000\n",
      "  Age group 61-70: 0.8148\n",
      "  Age group 71-80: 0.6667\n",
      "\n",
      "Demographic Parity:\n",
      "       Demographic Parity\n",
      "31-40            0.250000\n",
      "41-50            0.000000\n",
      "51-60            0.250000\n",
      "61-70            0.166667\n",
      "71-80            0.333333\n",
      "\n",
      "Equalized Odds:\n",
      "            TPR       FPR\n",
      "31-40  0.000000  0.333333\n",
      "41-50  0.000000  0.000000\n",
      "51-60  0.333333  0.000000\n",
      "61-70  0.500000  0.000000\n",
      "71-80  0.500000  0.000000\n",
      "\n",
      "=== Fairness Metrics for DenseNet121 ===\n",
      "Overall Accuracy: 0.7273\n",
      "Overall F1-Score: 0.6847\n",
      "\n",
      "Accuracy by Age Group:\n",
      "  Age group 31-40: 0.7500\n",
      "  Age group 41-50: 0.8000\n",
      "  Age group 51-60: 0.5000\n",
      "  Age group 61-70: 0.8333\n",
      "  Age group 71-80: 0.6667\n",
      "\n",
      "F1-Score by Age Group:\n",
      "  Age group 31-40: 0.6429\n",
      "  Age group 41-50: 0.7111\n",
      "  Age group 51-60: 0.5000\n",
      "  Age group 61-70: 0.8148\n",
      "  Age group 71-80: 0.6667\n",
      "\n",
      "Demographic Parity:\n",
      "       Demographic Parity\n",
      "31-40            0.000000\n",
      "41-50            0.000000\n",
      "51-60            0.250000\n",
      "61-70            0.166667\n",
      "71-80            0.333333\n",
      "\n",
      "Equalized Odds:\n",
      "            TPR  FPR\n",
      "31-40  0.000000  0.0\n",
      "41-50  0.000000  0.0\n",
      "51-60  0.333333  0.0\n",
      "61-70  0.500000  0.0\n",
      "71-80  0.500000  0.0\n",
      "\n",
      "=== Fairness Metrics for MobileNetV2 ===\n",
      "Overall Accuracy: 0.8182\n",
      "Overall F1-Score: 0.8133\n",
      "\n",
      "Accuracy by Age Group:\n",
      "  Age group 31-40: 0.7500\n",
      "  Age group 41-50: 0.6000\n",
      "  Age group 51-60: 0.7500\n",
      "  Age group 61-70: 1.0000\n",
      "  Age group 71-80: 1.0000\n",
      "\n",
      "F1-Score by Age Group:\n",
      "  Age group 31-40: 0.6429\n",
      "  Age group 41-50: 0.6000\n",
      "  Age group 51-60: 0.7667\n",
      "  Age group 61-70: 1.0000\n",
      "  Age group 71-80: 1.0000\n",
      "\n",
      "Demographic Parity:\n",
      "       Demographic Parity\n",
      "31-40            0.000000\n",
      "41-50            0.200000\n",
      "51-60            0.500000\n",
      "61-70            0.333333\n",
      "71-80            0.666667\n",
      "\n",
      "Equalized Odds:\n",
      "            TPR   FPR\n",
      "31-40  0.000000  0.00\n",
      "41-50  0.000000  0.25\n",
      "51-60  0.666667  0.00\n",
      "61-70  1.000000  0.00\n",
      "71-80  1.000000  0.00\n",
      "\n",
      "=== Fairness Metrics for AlexNet ===\n",
      "Overall Accuracy: 0.7273\n",
      "Overall F1-Score: 0.7200\n",
      "\n",
      "Accuracy by Age Group:\n",
      "  Age group 31-40: 0.7500\n",
      "  Age group 41-50: 0.6000\n",
      "  Age group 51-60: 0.5000\n",
      "  Age group 61-70: 1.0000\n",
      "  Age group 71-80: 0.6667\n",
      "\n",
      "F1-Score by Age Group:\n",
      "  Age group 31-40: 0.6429\n",
      "  Age group 41-50: 0.6000\n",
      "  Age group 51-60: 0.5000\n",
      "  Age group 61-70: 1.0000\n",
      "  Age group 71-80: 0.6667\n",
      "\n",
      "Demographic Parity:\n",
      "       Demographic Parity\n",
      "31-40            0.000000\n",
      "41-50            0.200000\n",
      "51-60            0.750000\n",
      "61-70            0.333333\n",
      "71-80            0.333333\n",
      "\n",
      "Equalized Odds:\n",
      "            TPR   FPR\n",
      "31-40  0.000000  0.00\n",
      "41-50  0.000000  0.25\n",
      "51-60  0.666667  1.00\n",
      "61-70  1.000000  0.00\n",
      "71-80  0.500000  0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def demographic_parity(labels, preds, protected_attrs):\n",
    "    dp = {}\n",
    "    for group in np.unique(protected_attrs):\n",
    "        group_mask = (protected_attrs == group)\n",
    "        dp[group] = np.mean(preds[group_mask])\n",
    "    return dp\n",
    "\n",
    "def equalized_odds(labels, preds, protected_attrs):\n",
    "    eo = {}\n",
    "    for group in np.unique(protected_attrs):\n",
    "        eo[group] = {}  # اصلاح نام متغیر group_eo به eo\n",
    "        group_mask = (protected_attrs == group)\n",
    "        group_labels = labels[group_mask]\n",
    "        group_preds = preds[group_mask]\n",
    "        tpr = np.sum((group_labels == 1) & (group_preds == 1)) / np.sum(group_labels == 1)\n",
    "        fpr = np.sum((group_labels == 0) & (group_preds == 1)) / np.sum(group_labels == 0)\n",
    "        eo[group] = {'TPR': tpr, 'FPR': fpr}\n",
    "    return eo\n",
    "    \n",
    "# Evaluate bias\n",
    "def evaluate_bias(model, dataloader, protected_attr_name):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_protected_attrs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "            protected_attrs = data[2]\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_protected_attrs.extend(protected_attrs)\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_protected_attrs = np.array(all_protected_attrs)\n",
    "\n",
    "    accuracy = np.mean(all_preds == all_labels)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    dp = demographic_parity(all_labels, all_preds, all_protected_attrs)\n",
    "    eo = equalized_odds(all_labels, all_preds, all_protected_attrs)\n",
    "\n",
    "    age_group_accuracies = {}\n",
    "    age_group_f1_scores = {}\n",
    "\n",
    "    for group in np.unique(all_protected_attrs):\n",
    "        group_mask = (all_protected_attrs == group)\n",
    "        group_labels = all_labels[group_mask]\n",
    "        group_preds = all_preds[group_mask]\n",
    "\n",
    "        group_accuracy = np.mean(group_preds == group_labels)\n",
    "        group_f1 = f1_score(group_labels, group_preds, average='weighted')\n",
    "\n",
    "        age_group_accuracies[group] = group_accuracy\n",
    "        age_group_f1_scores[group] = group_f1\n",
    "\n",
    "    return accuracy, f1, age_group_accuracies, age_group_f1_scores, dp, eo\n",
    "\n",
    "def print_fairness_metrics(model_name, accuracy, f1, age_group_accuracies, age_group_f1_scores, dp, eo):\n",
    "    print(f\"\\n=== Fairness Metrics for {model_name} ===\")\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Overall F1-Score: {f1:.4f}\")\n",
    "\n",
    "    print(\"\\nAccuracy by Age Group:\")\n",
    "    for age_group, group_accuracy in age_group_accuracies.items():\n",
    "        print(f\"  Age group {age_group}: {group_accuracy:.4f}\")\n",
    "\n",
    "    print(\"\\nF1-Score by Age Group:\")\n",
    "    for age_group, group_f1 in age_group_f1_scores.items():\n",
    "        print(f\"  Age group {age_group}: {group_f1:.4f}\")\n",
    "\n",
    "    print(\"\\nDemographic Parity:\")\n",
    "    dp_df = pd.DataFrame.from_dict(dp, orient='index', columns=['Demographic Parity'])\n",
    "    print(dp_df)\n",
    "\n",
    "    print(\"\\nEqualized Odds:\")\n",
    "    eo_df = pd.DataFrame.from_dict(eo, orient='index')\n",
    "    print(eo_df)\n",
    "\n",
    "for model, model_name in zip(trained_models, model_names):\n",
    "    accuracy, f1, age_group_accuracies, age_group_f1_scores, dp, eo = evaluate_bias(model, test_loader, protected_attr_name='Age_Category')\n",
    "    print_fairness_metrics(model_name, accuracy, f1, age_group_accuracies, age_group_f1_scores, dp, eo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44303625-7908-4023-8547-82ef60bf3b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
